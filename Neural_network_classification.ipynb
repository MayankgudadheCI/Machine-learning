{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Neural network classification.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "QSdEO7vyvjpI",
        "outputId": "37346d47-3065-4c9c-e25b-e4a86a456815"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "     Pregnancies  Glucose  BloodPressure  SkinThickness  Insulin   BMI  \\\n",
              "763           10      101             76             48      180  32.9   \n",
              "764            2      122             70             27        0  36.8   \n",
              "765            5      121             72             23      112  26.2   \n",
              "766            1      126             60              0        0  30.1   \n",
              "767            1       93             70             31        0  30.4   \n",
              "\n",
              "     DiabetesPedigreeFunction  Age  Outcome  \n",
              "763                     0.171   63        0  \n",
              "764                     0.340   27        0  \n",
              "765                     0.245   30        0  \n",
              "766                     0.349   47        1  \n",
              "767                     0.315   23        0  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-5716a702-9d29-4062-a095-304e27b43409\">\n",
              "    <div class=\"colab-df-container\">\n",
              "      <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Pregnancies</th>\n",
              "      <th>Glucose</th>\n",
              "      <th>BloodPressure</th>\n",
              "      <th>SkinThickness</th>\n",
              "      <th>Insulin</th>\n",
              "      <th>BMI</th>\n",
              "      <th>DiabetesPedigreeFunction</th>\n",
              "      <th>Age</th>\n",
              "      <th>Outcome</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>763</th>\n",
              "      <td>10</td>\n",
              "      <td>101</td>\n",
              "      <td>76</td>\n",
              "      <td>48</td>\n",
              "      <td>180</td>\n",
              "      <td>32.9</td>\n",
              "      <td>0.171</td>\n",
              "      <td>63</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>764</th>\n",
              "      <td>2</td>\n",
              "      <td>122</td>\n",
              "      <td>70</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "      <td>36.8</td>\n",
              "      <td>0.340</td>\n",
              "      <td>27</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>765</th>\n",
              "      <td>5</td>\n",
              "      <td>121</td>\n",
              "      <td>72</td>\n",
              "      <td>23</td>\n",
              "      <td>112</td>\n",
              "      <td>26.2</td>\n",
              "      <td>0.245</td>\n",
              "      <td>30</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>766</th>\n",
              "      <td>1</td>\n",
              "      <td>126</td>\n",
              "      <td>60</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>30.1</td>\n",
              "      <td>0.349</td>\n",
              "      <td>47</td>\n",
              "      <td>1</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>767</th>\n",
              "      <td>1</td>\n",
              "      <td>93</td>\n",
              "      <td>70</td>\n",
              "      <td>31</td>\n",
              "      <td>0</td>\n",
              "      <td>30.4</td>\n",
              "      <td>0.315</td>\n",
              "      <td>23</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "      <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-5716a702-9d29-4062-a095-304e27b43409')\"\n",
              "              title=\"Convert this dataframe to an interactive table.\"\n",
              "              style=\"display:none;\">\n",
              "        \n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M0 0h24v24H0V0z\" fill=\"none\"/>\n",
              "    <path d=\"M18.56 5.44l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94zm-11 1L8.5 8.5l.94-2.06 2.06-.94-2.06-.94L8.5 2.5l-.94 2.06-2.06.94zm10 10l.94 2.06.94-2.06 2.06-.94-2.06-.94-.94-2.06-.94 2.06-2.06.94z\"/><path d=\"M17.41 7.96l-1.37-1.37c-.4-.4-.92-.59-1.43-.59-.52 0-1.04.2-1.43.59L10.3 9.45l-7.72 7.72c-.78.78-.78 2.05 0 2.83L4 21.41c.39.39.9.59 1.41.59.51 0 1.02-.2 1.41-.59l7.78-7.78 2.81-2.81c.8-.78.8-2.07 0-2.86zM5.41 20L4 18.59l7.72-7.72 1.47 1.35L5.41 20z\"/>\n",
              "  </svg>\n",
              "      </button>\n",
              "      \n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      flex-wrap:wrap;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "      <script>\n",
              "        const buttonEl =\n",
              "          document.querySelector('#df-5716a702-9d29-4062-a095-304e27b43409 button.colab-df-convert');\n",
              "        buttonEl.style.display =\n",
              "          google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "        async function convertToInteractive(key) {\n",
              "          const element = document.querySelector('#df-5716a702-9d29-4062-a095-304e27b43409');\n",
              "          const dataTable =\n",
              "            await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                     [key], {});\n",
              "          if (!dataTable) return;\n",
              "\n",
              "          const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "            '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "            + ' to learn more about interactive tables.';\n",
              "          element.innerHTML = '';\n",
              "          dataTable['output_type'] = 'display_data';\n",
              "          await google.colab.output.renderOutput(dataTable, element);\n",
              "          const docLink = document.createElement('div');\n",
              "          docLink.innerHTML = docLinkHtml;\n",
              "          element.appendChild(docLink);\n",
              "        }\n",
              "      </script>\n",
              "    </div>\n",
              "  </div>\n",
              "  "
            ]
          },
          "metadata": {},
          "execution_count": 2
        }
      ],
      "source": [
        "import pandas as pd\n",
        "data = pd.read_csv(\"/content/drive/MyDrive/6th sem/Machine learning/diabetes (2).csv\")\n",
        "\n",
        "data.tail(5)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.columns"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "toVkNTlkyR5h",
        "outputId": "ac73f91f-7870-4e33-807b-32492c586f5c"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Index(['Pregnancies', 'Glucose', 'BloodPressure', 'SkinThickness', 'Insulin',\n",
              "       'BMI', 'DiabetesPedigreeFunction', 'Age', 'Outcome'],\n",
              "      dtype='object')"
            ]
          },
          "metadata": {},
          "execution_count": 3
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "data.values"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bRj409jTyyAf",
        "outputId": "7906ff05-a4ca-4ead-f4e2-843fdd3b7095"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[  6.   , 148.   ,  72.   , ...,   0.627,  50.   ,   1.   ],\n",
              "       [  1.   ,  85.   ,  66.   , ...,   0.351,  31.   ,   0.   ],\n",
              "       [  8.   , 183.   ,  64.   , ...,   0.672,  32.   ,   1.   ],\n",
              "       ...,\n",
              "       [  5.   , 121.   ,  72.   , ...,   0.245,  30.   ,   0.   ],\n",
              "       [  1.   , 126.   ,  60.   , ...,   0.349,  47.   ,   1.   ],\n",
              "       [  1.   ,  93.   ,  70.   , ...,   0.315,  23.   ,   0.   ]])"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "dataset=data.values\n",
        "x=dataset[:,0:8]\n",
        "y=dataset[:,8]\n",
        "print(x)\n",
        "print(y)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yZIp5SvwzQah",
        "outputId": "4396a765-211f-410d-e5a8-fd8362f27118"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[  6.    148.     72.    ...  33.6     0.627  50.   ]\n",
            " [  1.     85.     66.    ...  26.6     0.351  31.   ]\n",
            " [  8.    183.     64.    ...  23.3     0.672  32.   ]\n",
            " ...\n",
            " [  5.    121.     72.    ...  26.2     0.245  30.   ]\n",
            " [  1.    126.     60.    ...  30.1     0.349  47.   ]\n",
            " [  1.     93.     70.    ...  30.4     0.315  23.   ]]\n",
            "[1. 0. 1. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 1. 1. 1. 1. 1. 0. 1. 0. 0. 1. 1.\n",
            " 1. 1. 1. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0.\n",
            " 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 1. 1. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0.\n",
            " 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 1. 1. 0. 0.\n",
            " 1. 1. 0. 1. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 1.\n",
            " 1. 0. 1. 1. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 1. 1. 1. 1. 0.\n",
            " 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 1. 0. 0.\n",
            " 1. 0. 1. 0. 0. 1. 0. 1. 0. 1. 1. 1. 0. 0. 1. 0. 1. 0. 0. 0. 1. 0. 0. 0.\n",
            " 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 1. 1. 1. 0. 1.\n",
            " 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 1. 0. 1. 1. 0. 1. 0. 1. 0. 1. 0.\n",
            " 1. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 1. 0. 0.\n",
            " 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 1. 1. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0.\n",
            " 1. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0.\n",
            " 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 1. 1. 1. 0. 0. 1. 1. 0. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 0. 0.\n",
            " 0. 1. 0. 1. 1. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1. 0. 1. 0. 0. 1. 0. 0. 1. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 0. 1. 1. 0. 1. 0. 0. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 0. 1. 0. 0. 1. 0. 0. 0. 1. 0. 0. 0. 1. 1.\n",
            " 1. 0. 0. 0. 0. 0. 0. 1. 0. 0. 0. 1. 0. 1. 1. 1. 1. 0. 1. 1. 0. 0. 0. 0.\n",
            " 0. 0. 0. 1. 1. 0. 1. 0. 0. 1. 0. 1. 0. 0. 0. 0. 0. 1. 0. 1. 0. 1. 0. 1.\n",
            " 1. 0. 0. 0. 0. 1. 1. 0. 0. 0. 1. 0. 1. 1. 0. 0. 1. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 0. 0. 0. 0. 0. 0. 1. 1. 1. 0. 0. 0. 0. 0. 0. 1. 1. 0. 0. 1.\n",
            " 0. 0. 1. 0. 1. 1. 1. 0. 0. 1. 1. 1. 0. 1. 0. 1. 0. 1. 0. 0. 0. 0. 1. 0.]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn import preprocessing\n",
        "min_max_scaler = preprocessing.MinMaxScaler()\n",
        "x_scale =min_max_scaler.fit_transform(x)\n",
        "x_scale"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kzngpoi01WNz",
        "outputId": "c622e363-a758-4d3a-913a-d028b2f2afca"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.35294118, 0.74371859, 0.59016393, ..., 0.50074516, 0.23441503,\n",
              "        0.48333333],\n",
              "       [0.05882353, 0.42713568, 0.54098361, ..., 0.39642325, 0.11656704,\n",
              "        0.16666667],\n",
              "       [0.47058824, 0.91959799, 0.52459016, ..., 0.34724292, 0.25362938,\n",
              "        0.18333333],\n",
              "       ...,\n",
              "       [0.29411765, 0.6080402 , 0.59016393, ..., 0.390462  , 0.07130658,\n",
              "        0.15      ],\n",
              "       [0.05882353, 0.63316583, 0.49180328, ..., 0.4485842 , 0.11571307,\n",
              "        0.43333333],\n",
              "       [0.05882353, 0.46733668, 0.57377049, ..., 0.45305514, 0.10119556,\n",
              "        0.03333333]])"
            ]
          },
          "metadata": {},
          "execution_count": 6
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.utils import np_utils\n",
        "encoded_y =np_utils.to_categorical(y)\n",
        "encoded_y"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hp0cFKwm2lH_",
        "outputId": "29604636-1010-41af-fdb0-d7a035b3644b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0., 1.],\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       ...,\n",
              "       [1., 0.],\n",
              "       [0., 1.],\n",
              "       [1., 0.]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "x_training,x_testing,y_training,y_testing=train_test_split(x_scale,encoded_y,test_size=0.2,random_state=10)\n",
        "x_training,x_valid,y_training,y_valid=train_test_split(x_training,y_training,test_size=0.2,random_state=10)\n",
        "print(len(x_training))\n",
        "print(len(x_testing))\n",
        "print(len(x_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AFyrJ-3z4INe",
        "outputId": "25f20be6-8793-4242-8b65-13b9bb4f2b1e"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "491\n",
            "154\n",
            "123\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "#creating the model\n",
        "model = Sequential()\n",
        "model.add(Dense(24, input_shape=(8,),activation='relu'))\n",
        "model.add(Dense(20, activation= 'relu'))\n",
        "model.add(Dense(12, activation= 'tanh'))\n",
        "model.add(Dense(8, activation= 'relu'))\n",
        "model.add(Dense(2, activation= 'softmax'))\n",
        "#gives a  summary of the model\n",
        "model.summary()\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "juxT-_Xm71fd",
        "outputId": "59ae6b23-9cc5-4b35-e391-6bfde96a6432"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 24)                216       \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 20)                500       \n",
            "                                                                 \n",
            " dense_2 (Dense)             (None, 12)                252       \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 8)                 104       \n",
            "                                                                 \n",
            " dense_4 (Dense)             (None, 2)                 18        \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 1,090\n",
            "Trainable params: 1,090\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from tensorflow.keras import optimizers\n",
        "opt=optimizers.SGD(learning_rate=0.01)\n",
        "model.compile(loss='categorical_crossentropy',optimizer=opt,metrics=['accuracy'])"
      ],
      "metadata": {
        "id": "Vb2rQzy79ItR"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "hist = model.fit(x_training, y_training, batch_size=4 ,epochs=750 , validation_data=(x_valid,y_valid))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WRLKV1EK_Lz4",
        "outputId": "a93004f1-fdd2-4365-b09e-f1abd4f40afe"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0910 - accuracy: 0.9695 - val_loss: 1.4767 - val_accuracy: 0.7317\n",
            "Epoch 2/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0888 - accuracy: 0.9633 - val_loss: 1.6071 - val_accuracy: 0.7073\n",
            "Epoch 3/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0872 - accuracy: 0.9695 - val_loss: 1.6259 - val_accuracy: 0.6992\n",
            "Epoch 4/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0727 - accuracy: 0.9715 - val_loss: 1.7232 - val_accuracy: 0.7073\n",
            "Epoch 5/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0467 - accuracy: 0.9857 - val_loss: 1.7562 - val_accuracy: 0.6992\n",
            "Epoch 6/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0964 - accuracy: 0.9572 - val_loss: 1.4983 - val_accuracy: 0.6911\n",
            "Epoch 7/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0899 - accuracy: 0.9654 - val_loss: 1.5721 - val_accuracy: 0.7154\n",
            "Epoch 8/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0535 - accuracy: 0.9796 - val_loss: 1.7814 - val_accuracy: 0.6992\n",
            "Epoch 9/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0748 - accuracy: 0.9756 - val_loss: 1.6424 - val_accuracy: 0.6992\n",
            "Epoch 10/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9613 - val_loss: 1.5592 - val_accuracy: 0.7073\n",
            "Epoch 11/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1017 - accuracy: 0.9593 - val_loss: 1.8477 - val_accuracy: 0.7073\n",
            "Epoch 12/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0790 - accuracy: 0.9715 - val_loss: 1.7755 - val_accuracy: 0.7236\n",
            "Epoch 13/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0731 - accuracy: 0.9695 - val_loss: 1.5435 - val_accuracy: 0.6992\n",
            "Epoch 14/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9756 - val_loss: 1.7762 - val_accuracy: 0.6992\n",
            "Epoch 15/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1467 - accuracy: 0.9532 - val_loss: 1.6564 - val_accuracy: 0.7236\n",
            "Epoch 16/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0761 - accuracy: 0.9796 - val_loss: 1.9584 - val_accuracy: 0.7073\n",
            "Epoch 17/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0871 - accuracy: 0.9756 - val_loss: 1.6781 - val_accuracy: 0.7073\n",
            "Epoch 18/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0745 - accuracy: 0.9695 - val_loss: 1.9093 - val_accuracy: 0.7154\n",
            "Epoch 19/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1472 - accuracy: 0.9470 - val_loss: 1.6492 - val_accuracy: 0.7154\n",
            "Epoch 20/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0717 - accuracy: 0.9695 - val_loss: 1.7248 - val_accuracy: 0.7073\n",
            "Epoch 21/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0514 - accuracy: 0.9817 - val_loss: 1.6773 - val_accuracy: 0.6992\n",
            "Epoch 22/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0830 - accuracy: 0.9674 - val_loss: 1.5770 - val_accuracy: 0.7073\n",
            "Epoch 23/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0667 - accuracy: 0.9674 - val_loss: 1.7560 - val_accuracy: 0.6992\n",
            "Epoch 24/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1024 - accuracy: 0.9572 - val_loss: 1.7095 - val_accuracy: 0.7236\n",
            "Epoch 25/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0552 - accuracy: 0.9878 - val_loss: 1.8126 - val_accuracy: 0.6911\n",
            "Epoch 26/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0685 - accuracy: 0.9756 - val_loss: 1.7023 - val_accuracy: 0.6911\n",
            "Epoch 27/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0795 - accuracy: 0.9695 - val_loss: 1.6474 - val_accuracy: 0.7317\n",
            "Epoch 28/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1049 - accuracy: 0.9695 - val_loss: 1.8238 - val_accuracy: 0.6992\n",
            "Epoch 29/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1151 - accuracy: 0.9552 - val_loss: 1.6509 - val_accuracy: 0.7317\n",
            "Epoch 30/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0874 - accuracy: 0.9654 - val_loss: 1.5783 - val_accuracy: 0.7073\n",
            "Epoch 31/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0629 - accuracy: 0.9796 - val_loss: 1.7401 - val_accuracy: 0.7236\n",
            "Epoch 32/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9695 - val_loss: 1.9053 - val_accuracy: 0.7154\n",
            "Epoch 33/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1123 - accuracy: 0.9491 - val_loss: 1.5781 - val_accuracy: 0.7236\n",
            "Epoch 34/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0813 - accuracy: 0.9654 - val_loss: 1.6776 - val_accuracy: 0.6911\n",
            "Epoch 35/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0633 - accuracy: 0.9796 - val_loss: 1.7307 - val_accuracy: 0.6992\n",
            "Epoch 36/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0692 - accuracy: 0.9796 - val_loss: 1.7663 - val_accuracy: 0.7073\n",
            "Epoch 37/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1236 - accuracy: 0.9511 - val_loss: 1.6687 - val_accuracy: 0.7317\n",
            "Epoch 38/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1372 - accuracy: 0.9470 - val_loss: 1.4243 - val_accuracy: 0.7480\n",
            "Epoch 39/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0781 - accuracy: 0.9633 - val_loss: 1.7587 - val_accuracy: 0.6992\n",
            "Epoch 40/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0703 - accuracy: 0.9735 - val_loss: 1.7827 - val_accuracy: 0.6992\n",
            "Epoch 41/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0724 - accuracy: 0.9715 - val_loss: 1.5851 - val_accuracy: 0.7154\n",
            "Epoch 42/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0719 - accuracy: 0.9715 - val_loss: 1.8197 - val_accuracy: 0.6992\n",
            "Epoch 43/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9837 - val_loss: 1.8321 - val_accuracy: 0.7073\n",
            "Epoch 44/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0441 - accuracy: 0.9878 - val_loss: 1.7976 - val_accuracy: 0.7154\n",
            "Epoch 45/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9878 - val_loss: 1.7912 - val_accuracy: 0.7073\n",
            "Epoch 46/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0553 - accuracy: 0.9817 - val_loss: 1.7389 - val_accuracy: 0.7317\n",
            "Epoch 47/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0521 - accuracy: 0.9857 - val_loss: 1.7775 - val_accuracy: 0.7236\n",
            "Epoch 48/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0806 - accuracy: 0.9633 - val_loss: 1.7082 - val_accuracy: 0.7073\n",
            "Epoch 49/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0411 - accuracy: 0.9898 - val_loss: 1.7389 - val_accuracy: 0.7236\n",
            "Epoch 50/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0443 - accuracy: 0.9857 - val_loss: 1.9026 - val_accuracy: 0.7317\n",
            "Epoch 51/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0581 - accuracy: 0.9756 - val_loss: 1.8686 - val_accuracy: 0.7154\n",
            "Epoch 52/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0391 - accuracy: 0.9878 - val_loss: 1.9837 - val_accuracy: 0.6992\n",
            "Epoch 53/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1458 - accuracy: 0.9450 - val_loss: 1.7272 - val_accuracy: 0.7236\n",
            "Epoch 54/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0700 - accuracy: 0.9776 - val_loss: 1.8072 - val_accuracy: 0.7073\n",
            "Epoch 55/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0437 - accuracy: 0.9837 - val_loss: 1.8893 - val_accuracy: 0.7073\n",
            "Epoch 56/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0586 - accuracy: 0.9776 - val_loss: 1.9401 - val_accuracy: 0.7073\n",
            "Epoch 57/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0466 - accuracy: 0.9878 - val_loss: 1.9909 - val_accuracy: 0.6911\n",
            "Epoch 58/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0499 - accuracy: 0.9796 - val_loss: 1.7756 - val_accuracy: 0.6829\n",
            "Epoch 59/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0778 - accuracy: 0.9715 - val_loss: 1.8950 - val_accuracy: 0.6911\n",
            "Epoch 60/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1761 - accuracy: 0.9328 - val_loss: 1.8930 - val_accuracy: 0.6992\n",
            "Epoch 61/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0765 - accuracy: 0.9654 - val_loss: 1.6876 - val_accuracy: 0.6911\n",
            "Epoch 62/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1510 - accuracy: 0.9491 - val_loss: 1.9399 - val_accuracy: 0.7073\n",
            "Epoch 63/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0878 - accuracy: 0.9654 - val_loss: 1.8168 - val_accuracy: 0.6911\n",
            "Epoch 64/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1423 - accuracy: 0.9491 - val_loss: 1.9867 - val_accuracy: 0.7236\n",
            "Epoch 65/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0944 - accuracy: 0.9532 - val_loss: 1.9227 - val_accuracy: 0.7154\n",
            "Epoch 66/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1365 - accuracy: 0.9491 - val_loss: 1.9079 - val_accuracy: 0.7154\n",
            "Epoch 67/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2543 - accuracy: 0.9022 - val_loss: 1.6415 - val_accuracy: 0.7236\n",
            "Epoch 68/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1150 - accuracy: 0.9572 - val_loss: 1.5914 - val_accuracy: 0.6992\n",
            "Epoch 69/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0570 - accuracy: 0.9776 - val_loss: 1.7228 - val_accuracy: 0.7317\n",
            "Epoch 70/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0450 - accuracy: 0.9776 - val_loss: 1.7061 - val_accuracy: 0.7154\n",
            "Epoch 71/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0415 - accuracy: 0.9898 - val_loss: 1.6972 - val_accuracy: 0.7154\n",
            "Epoch 72/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0388 - accuracy: 0.9878 - val_loss: 1.7213 - val_accuracy: 0.6992\n",
            "Epoch 73/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1122 - accuracy: 0.9613 - val_loss: 1.6605 - val_accuracy: 0.7236\n",
            "Epoch 74/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1026 - accuracy: 0.9633 - val_loss: 1.7766 - val_accuracy: 0.7154\n",
            "Epoch 75/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0876 - accuracy: 0.9633 - val_loss: 1.8892 - val_accuracy: 0.6992\n",
            "Epoch 76/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0818 - accuracy: 0.9654 - val_loss: 1.7983 - val_accuracy: 0.7073\n",
            "Epoch 77/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0500 - accuracy: 0.9857 - val_loss: 1.7144 - val_accuracy: 0.7154\n",
            "Epoch 78/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0475 - accuracy: 0.9837 - val_loss: 1.8426 - val_accuracy: 0.6992\n",
            "Epoch 79/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9959 - val_loss: 1.8569 - val_accuracy: 0.7154\n",
            "Epoch 80/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0285 - accuracy: 0.9959 - val_loss: 1.8511 - val_accuracy: 0.6992\n",
            "Epoch 81/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9695 - val_loss: 1.6593 - val_accuracy: 0.7317\n",
            "Epoch 82/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0488 - accuracy: 0.9796 - val_loss: 1.8853 - val_accuracy: 0.6829\n",
            "Epoch 83/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0637 - accuracy: 0.9776 - val_loss: 1.8566 - val_accuracy: 0.7154\n",
            "Epoch 84/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0966 - accuracy: 0.9776 - val_loss: 1.8806 - val_accuracy: 0.7236\n",
            "Epoch 85/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1300 - accuracy: 0.9593 - val_loss: 1.8811 - val_accuracy: 0.6829\n",
            "Epoch 86/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1294 - accuracy: 0.9552 - val_loss: 1.7985 - val_accuracy: 0.6911\n",
            "Epoch 87/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2196 - accuracy: 0.9287 - val_loss: 1.7082 - val_accuracy: 0.7236\n",
            "Epoch 88/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1394 - accuracy: 0.9450 - val_loss: 1.7877 - val_accuracy: 0.6992\n",
            "Epoch 89/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0773 - accuracy: 0.9613 - val_loss: 1.8119 - val_accuracy: 0.7073\n",
            "Epoch 90/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0839 - accuracy: 0.9613 - val_loss: 1.7726 - val_accuracy: 0.7317\n",
            "Epoch 91/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0436 - accuracy: 0.9878 - val_loss: 1.8288 - val_accuracy: 0.6992\n",
            "Epoch 92/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0393 - accuracy: 0.9857 - val_loss: 1.8428 - val_accuracy: 0.6992\n",
            "Epoch 93/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0329 - accuracy: 0.9939 - val_loss: 1.8357 - val_accuracy: 0.7073\n",
            "Epoch 94/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0372 - accuracy: 0.9898 - val_loss: 1.9055 - val_accuracy: 0.7154\n",
            "Epoch 95/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0442 - accuracy: 0.9878 - val_loss: 1.9215 - val_accuracy: 0.7073\n",
            "Epoch 96/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0345 - accuracy: 0.9939 - val_loss: 1.8970 - val_accuracy: 0.7073\n",
            "Epoch 97/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0281 - accuracy: 0.9898 - val_loss: 1.9286 - val_accuracy: 0.7073\n",
            "Epoch 98/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9939 - val_loss: 1.9198 - val_accuracy: 0.6911\n",
            "Epoch 99/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0252 - accuracy: 0.9959 - val_loss: 1.9350 - val_accuracy: 0.7073\n",
            "Epoch 100/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0234 - accuracy: 0.9980 - val_loss: 1.9813 - val_accuracy: 0.7073\n",
            "Epoch 101/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9939 - val_loss: 1.9157 - val_accuracy: 0.7073\n",
            "Epoch 102/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0861 - accuracy: 0.9715 - val_loss: 2.0312 - val_accuracy: 0.7236\n",
            "Epoch 103/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.4058 - accuracy: 0.8778 - val_loss: 1.7612 - val_accuracy: 0.6829\n",
            "Epoch 104/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.2610 - accuracy: 0.9226 - val_loss: 1.6734 - val_accuracy: 0.6098\n",
            "Epoch 105/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0905 - accuracy: 0.9613 - val_loss: 1.6771 - val_accuracy: 0.7236\n",
            "Epoch 106/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0580 - accuracy: 0.9756 - val_loss: 1.7092 - val_accuracy: 0.7236\n",
            "Epoch 107/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0433 - accuracy: 0.9837 - val_loss: 1.7423 - val_accuracy: 0.6911\n",
            "Epoch 108/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9959 - val_loss: 1.6922 - val_accuracy: 0.7236\n",
            "Epoch 109/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0272 - accuracy: 0.9919 - val_loss: 1.8139 - val_accuracy: 0.7073\n",
            "Epoch 110/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0361 - accuracy: 0.9919 - val_loss: 1.7609 - val_accuracy: 0.7154\n",
            "Epoch 111/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0274 - accuracy: 0.9980 - val_loss: 1.9175 - val_accuracy: 0.6992\n",
            "Epoch 112/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0287 - accuracy: 0.9939 - val_loss: 1.9370 - val_accuracy: 0.6992\n",
            "Epoch 113/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0279 - accuracy: 0.9939 - val_loss: 1.8741 - val_accuracy: 0.7073\n",
            "Epoch 114/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9980 - val_loss: 1.9630 - val_accuracy: 0.6992\n",
            "Epoch 115/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0428 - accuracy: 0.9898 - val_loss: 1.7914 - val_accuracy: 0.6829\n",
            "Epoch 116/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0498 - accuracy: 0.9837 - val_loss: 1.8696 - val_accuracy: 0.7317\n",
            "Epoch 117/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0239 - accuracy: 0.9939 - val_loss: 1.8694 - val_accuracy: 0.7236\n",
            "Epoch 118/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0278 - accuracy: 0.9919 - val_loss: 1.7988 - val_accuracy: 0.7073\n",
            "Epoch 119/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0179 - accuracy: 1.0000 - val_loss: 1.9660 - val_accuracy: 0.6992\n",
            "Epoch 120/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0219 - accuracy: 0.9939 - val_loss: 1.9823 - val_accuracy: 0.7073\n",
            "Epoch 121/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0306 - accuracy: 0.9898 - val_loss: 2.0890 - val_accuracy: 0.6911\n",
            "Epoch 122/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0248 - accuracy: 0.9959 - val_loss: 1.8987 - val_accuracy: 0.6992\n",
            "Epoch 123/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0752 - accuracy: 0.9654 - val_loss: 2.0303 - val_accuracy: 0.6992\n",
            "Epoch 124/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0676 - accuracy: 0.9674 - val_loss: 1.8821 - val_accuracy: 0.6992\n",
            "Epoch 125/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0377 - accuracy: 0.9857 - val_loss: 1.8672 - val_accuracy: 0.7073\n",
            "Epoch 126/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0908 - accuracy: 0.9695 - val_loss: 2.0465 - val_accuracy: 0.6992\n",
            "Epoch 127/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1310 - accuracy: 0.9511 - val_loss: 1.8198 - val_accuracy: 0.6992\n",
            "Epoch 128/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0583 - accuracy: 0.9776 - val_loss: 1.8892 - val_accuracy: 0.7236\n",
            "Epoch 129/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0292 - accuracy: 0.9939 - val_loss: 1.8672 - val_accuracy: 0.7154\n",
            "Epoch 130/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0458 - accuracy: 0.9857 - val_loss: 1.7527 - val_accuracy: 0.6992\n",
            "Epoch 131/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1720 - accuracy: 0.9450 - val_loss: 2.0078 - val_accuracy: 0.6992\n",
            "Epoch 132/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.1855 - accuracy: 0.9308 - val_loss: 1.7013 - val_accuracy: 0.7317\n",
            "Epoch 133/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0304 - accuracy: 0.9959 - val_loss: 1.7779 - val_accuracy: 0.7236\n",
            "Epoch 134/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0236 - accuracy: 0.9959 - val_loss: 1.8083 - val_accuracy: 0.7154\n",
            "Epoch 135/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0242 - accuracy: 0.9939 - val_loss: 1.7848 - val_accuracy: 0.7154\n",
            "Epoch 136/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0185 - accuracy: 0.9980 - val_loss: 1.8568 - val_accuracy: 0.7154\n",
            "Epoch 137/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0200 - accuracy: 0.9980 - val_loss: 1.8373 - val_accuracy: 0.7073\n",
            "Epoch 138/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9959 - val_loss: 1.8783 - val_accuracy: 0.7073\n",
            "Epoch 139/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0191 - accuracy: 0.9959 - val_loss: 1.9036 - val_accuracy: 0.7154\n",
            "Epoch 140/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0204 - accuracy: 0.9959 - val_loss: 1.8422 - val_accuracy: 0.7073\n",
            "Epoch 141/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0197 - accuracy: 0.9980 - val_loss: 1.8554 - val_accuracy: 0.6992\n",
            "Epoch 142/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0520 - accuracy: 0.9817 - val_loss: 1.9086 - val_accuracy: 0.7154\n",
            "Epoch 143/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0233 - accuracy: 0.9959 - val_loss: 1.9826 - val_accuracy: 0.6992\n",
            "Epoch 144/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0163 - accuracy: 0.9980 - val_loss: 1.8142 - val_accuracy: 0.7236\n",
            "Epoch 145/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0177 - accuracy: 0.9959 - val_loss: 1.9179 - val_accuracy: 0.7154\n",
            "Epoch 146/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0154 - accuracy: 0.9980 - val_loss: 1.9552 - val_accuracy: 0.7073\n",
            "Epoch 147/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0155 - accuracy: 0.9980 - val_loss: 1.9144 - val_accuracy: 0.7154\n",
            "Epoch 148/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0188 - accuracy: 0.9959 - val_loss: 1.9787 - val_accuracy: 0.7236\n",
            "Epoch 149/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9980 - val_loss: 1.9930 - val_accuracy: 0.7236\n",
            "Epoch 150/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0143 - accuracy: 0.9980 - val_loss: 2.0595 - val_accuracy: 0.7073\n",
            "Epoch 151/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0135 - accuracy: 0.9980 - val_loss: 2.0004 - val_accuracy: 0.7236\n",
            "Epoch 152/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0160 - accuracy: 0.9959 - val_loss: 2.0953 - val_accuracy: 0.7154\n",
            "Epoch 153/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0133 - accuracy: 0.9980 - val_loss: 2.0884 - val_accuracy: 0.7154\n",
            "Epoch 154/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0127 - accuracy: 0.9959 - val_loss: 2.0137 - val_accuracy: 0.7073\n",
            "Epoch 155/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0123 - accuracy: 0.9980 - val_loss: 2.0216 - val_accuracy: 0.7236\n",
            "Epoch 156/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0128 - accuracy: 0.9980 - val_loss: 2.0709 - val_accuracy: 0.7073\n",
            "Epoch 157/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0113 - accuracy: 1.0000 - val_loss: 2.1110 - val_accuracy: 0.7073\n",
            "Epoch 158/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0142 - accuracy: 0.9939 - val_loss: 1.9779 - val_accuracy: 0.7154\n",
            "Epoch 159/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 0.9980 - val_loss: 1.9886 - val_accuracy: 0.7154\n",
            "Epoch 160/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0122 - accuracy: 1.0000 - val_loss: 2.0014 - val_accuracy: 0.7154\n",
            "Epoch 161/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0092 - accuracy: 1.0000 - val_loss: 2.0096 - val_accuracy: 0.7154\n",
            "Epoch 162/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0089 - accuracy: 1.0000 - val_loss: 2.0464 - val_accuracy: 0.6992\n",
            "Epoch 163/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0109 - accuracy: 0.9980 - val_loss: 2.0374 - val_accuracy: 0.7236\n",
            "Epoch 164/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0110 - accuracy: 0.9980 - val_loss: 2.0674 - val_accuracy: 0.7073\n",
            "Epoch 165/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0106 - accuracy: 0.9959 - val_loss: 2.0712 - val_accuracy: 0.7236\n",
            "Epoch 166/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0097 - accuracy: 0.9980 - val_loss: 2.0997 - val_accuracy: 0.6992\n",
            "Epoch 167/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0083 - accuracy: 1.0000 - val_loss: 2.0268 - val_accuracy: 0.7236\n",
            "Epoch 168/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.0978 - val_accuracy: 0.7073\n",
            "Epoch 169/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0087 - accuracy: 1.0000 - val_loss: 2.1320 - val_accuracy: 0.7073\n",
            "Epoch 170/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1957 - val_accuracy: 0.6911\n",
            "Epoch 171/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0095 - accuracy: 0.9980 - val_loss: 2.1226 - val_accuracy: 0.7236\n",
            "Epoch 172/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0103 - accuracy: 0.9980 - val_loss: 2.1573 - val_accuracy: 0.6992\n",
            "Epoch 173/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0082 - accuracy: 1.0000 - val_loss: 2.2064 - val_accuracy: 0.7073\n",
            "Epoch 174/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.2080 - val_accuracy: 0.7073\n",
            "Epoch 175/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0079 - accuracy: 1.0000 - val_loss: 2.1751 - val_accuracy: 0.6992\n",
            "Epoch 176/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0073 - accuracy: 1.0000 - val_loss: 2.1704 - val_accuracy: 0.7073\n",
            "Epoch 177/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.1821 - val_accuracy: 0.7154\n",
            "Epoch 178/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1232 - val_accuracy: 0.7154\n",
            "Epoch 179/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0078 - accuracy: 1.0000 - val_loss: 2.2168 - val_accuracy: 0.6992\n",
            "Epoch 180/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0070 - accuracy: 1.0000 - val_loss: 2.1825 - val_accuracy: 0.7073\n",
            "Epoch 181/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0067 - accuracy: 1.0000 - val_loss: 2.1669 - val_accuracy: 0.7236\n",
            "Epoch 182/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0065 - accuracy: 1.0000 - val_loss: 2.1802 - val_accuracy: 0.7073\n",
            "Epoch 183/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0066 - accuracy: 1.0000 - val_loss: 2.1599 - val_accuracy: 0.7236\n",
            "Epoch 184/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0080 - accuracy: 1.0000 - val_loss: 2.2223 - val_accuracy: 0.6992\n",
            "Epoch 185/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.2138 - val_accuracy: 0.6992\n",
            "Epoch 186/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0060 - accuracy: 1.0000 - val_loss: 2.2411 - val_accuracy: 0.6992\n",
            "Epoch 187/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2028 - val_accuracy: 0.7073\n",
            "Epoch 188/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.2729 - val_accuracy: 0.6911\n",
            "Epoch 189/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0063 - accuracy: 1.0000 - val_loss: 2.2343 - val_accuracy: 0.7154\n",
            "Epoch 190/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0059 - accuracy: 1.0000 - val_loss: 2.2737 - val_accuracy: 0.6992\n",
            "Epoch 191/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.2829 - val_accuracy: 0.6992\n",
            "Epoch 192/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0051 - accuracy: 1.0000 - val_loss: 2.2478 - val_accuracy: 0.7073\n",
            "Epoch 193/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0057 - accuracy: 1.0000 - val_loss: 2.2711 - val_accuracy: 0.6992\n",
            "Epoch 194/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.2934 - val_accuracy: 0.6911\n",
            "Epoch 195/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0049 - accuracy: 1.0000 - val_loss: 2.2587 - val_accuracy: 0.7154\n",
            "Epoch 196/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.2855 - val_accuracy: 0.6992\n",
            "Epoch 197/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0054 - accuracy: 1.0000 - val_loss: 2.2911 - val_accuracy: 0.6992\n",
            "Epoch 198/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0052 - accuracy: 1.0000 - val_loss: 2.2728 - val_accuracy: 0.7073\n",
            "Epoch 199/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0053 - accuracy: 1.0000 - val_loss: 2.3056 - val_accuracy: 0.6992\n",
            "Epoch 200/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.2711 - val_accuracy: 0.7073\n",
            "Epoch 201/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0042 - accuracy: 1.0000 - val_loss: 2.3517 - val_accuracy: 0.6992\n",
            "Epoch 202/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3365 - val_accuracy: 0.6992\n",
            "Epoch 203/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0046 - accuracy: 1.0000 - val_loss: 2.3437 - val_accuracy: 0.6992\n",
            "Epoch 204/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3556 - val_accuracy: 0.6911\n",
            "Epoch 205/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3494 - val_accuracy: 0.7073\n",
            "Epoch 206/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0045 - accuracy: 1.0000 - val_loss: 2.3371 - val_accuracy: 0.7073\n",
            "Epoch 207/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3339 - val_accuracy: 0.6992\n",
            "Epoch 208/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0044 - accuracy: 1.0000 - val_loss: 2.3754 - val_accuracy: 0.6992\n",
            "Epoch 209/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0043 - accuracy: 1.0000 - val_loss: 2.3479 - val_accuracy: 0.7073\n",
            "Epoch 210/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3490 - val_accuracy: 0.7073\n",
            "Epoch 211/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3536 - val_accuracy: 0.6992\n",
            "Epoch 212/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0040 - accuracy: 1.0000 - val_loss: 2.3351 - val_accuracy: 0.7073\n",
            "Epoch 213/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0041 - accuracy: 1.0000 - val_loss: 2.3426 - val_accuracy: 0.7073\n",
            "Epoch 214/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3779 - val_accuracy: 0.6992\n",
            "Epoch 215/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3816 - val_accuracy: 0.7073\n",
            "Epoch 216/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4025 - val_accuracy: 0.6992\n",
            "Epoch 217/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0039 - accuracy: 1.0000 - val_loss: 2.3868 - val_accuracy: 0.7073\n",
            "Epoch 218/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4131 - val_accuracy: 0.6992\n",
            "Epoch 219/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4051 - val_accuracy: 0.6992\n",
            "Epoch 220/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0037 - accuracy: 1.0000 - val_loss: 2.4086 - val_accuracy: 0.7073\n",
            "Epoch 221/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0035 - accuracy: 1.0000 - val_loss: 2.4446 - val_accuracy: 0.6992\n",
            "Epoch 222/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0038 - accuracy: 1.0000 - val_loss: 2.4069 - val_accuracy: 0.7073\n",
            "Epoch 223/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0036 - accuracy: 1.0000 - val_loss: 2.4010 - val_accuracy: 0.6992\n",
            "Epoch 224/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4265 - val_accuracy: 0.7073\n",
            "Epoch 225/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.4389 - val_accuracy: 0.7073\n",
            "Epoch 226/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.3804 - val_accuracy: 0.7154\n",
            "Epoch 227/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4320 - val_accuracy: 0.6911\n",
            "Epoch 228/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0034 - accuracy: 1.0000 - val_loss: 2.4490 - val_accuracy: 0.7073\n",
            "Epoch 229/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0033 - accuracy: 1.0000 - val_loss: 2.4284 - val_accuracy: 0.6992\n",
            "Epoch 230/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4281 - val_accuracy: 0.6992\n",
            "Epoch 231/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4555 - val_accuracy: 0.7073\n",
            "Epoch 232/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4342 - val_accuracy: 0.6992\n",
            "Epoch 233/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4636 - val_accuracy: 0.7073\n",
            "Epoch 234/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0032 - accuracy: 1.0000 - val_loss: 2.4382 - val_accuracy: 0.7073\n",
            "Epoch 235/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4549 - val_accuracy: 0.6992\n",
            "Epoch 236/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4589 - val_accuracy: 0.7073\n",
            "Epoch 237/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4446 - val_accuracy: 0.7073\n",
            "Epoch 238/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0031 - accuracy: 1.0000 - val_loss: 2.4696 - val_accuracy: 0.7073\n",
            "Epoch 239/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4813 - val_accuracy: 0.6992\n",
            "Epoch 240/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0030 - accuracy: 1.0000 - val_loss: 2.4645 - val_accuracy: 0.6992\n",
            "Epoch 241/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.4731 - val_accuracy: 0.7073\n",
            "Epoch 242/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4892 - val_accuracy: 0.6992\n",
            "Epoch 243/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0029 - accuracy: 1.0000 - val_loss: 2.5071 - val_accuracy: 0.6992\n",
            "Epoch 244/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4764 - val_accuracy: 0.7073\n",
            "Epoch 245/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4850 - val_accuracy: 0.6992\n",
            "Epoch 246/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4966 - val_accuracy: 0.7073\n",
            "Epoch 247/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0028 - accuracy: 1.0000 - val_loss: 2.4931 - val_accuracy: 0.7073\n",
            "Epoch 248/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.5003 - val_accuracy: 0.7073\n",
            "Epoch 249/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4969 - val_accuracy: 0.7073\n",
            "Epoch 250/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.4949 - val_accuracy: 0.7073\n",
            "Epoch 251/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5157 - val_accuracy: 0.6992\n",
            "Epoch 252/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0027 - accuracy: 1.0000 - val_loss: 2.5016 - val_accuracy: 0.7073\n",
            "Epoch 253/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5170 - val_accuracy: 0.6992\n",
            "Epoch 254/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5134 - val_accuracy: 0.6992\n",
            "Epoch 255/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0026 - accuracy: 1.0000 - val_loss: 2.5211 - val_accuracy: 0.6992\n",
            "Epoch 256/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5352 - val_accuracy: 0.7073\n",
            "Epoch 257/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5422 - val_accuracy: 0.7073\n",
            "Epoch 258/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5371 - val_accuracy: 0.7073\n",
            "Epoch 259/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5541 - val_accuracy: 0.7073\n",
            "Epoch 260/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0025 - accuracy: 1.0000 - val_loss: 2.5329 - val_accuracy: 0.6992\n",
            "Epoch 261/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5124 - val_accuracy: 0.7073\n",
            "Epoch 262/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5610 - val_accuracy: 0.6992\n",
            "Epoch 263/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5558 - val_accuracy: 0.7073\n",
            "Epoch 264/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5603 - val_accuracy: 0.7073\n",
            "Epoch 265/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0024 - accuracy: 1.0000 - val_loss: 2.5678 - val_accuracy: 0.6992\n",
            "Epoch 266/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5756 - val_accuracy: 0.6992\n",
            "Epoch 267/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5615 - val_accuracy: 0.7073\n",
            "Epoch 268/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5554 - val_accuracy: 0.7073\n",
            "Epoch 269/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0023 - accuracy: 1.0000 - val_loss: 2.5658 - val_accuracy: 0.7073\n",
            "Epoch 270/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5751 - val_accuracy: 0.6992\n",
            "Epoch 271/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5834 - val_accuracy: 0.7073\n",
            "Epoch 272/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.6020 - val_accuracy: 0.6992\n",
            "Epoch 273/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5624 - val_accuracy: 0.7073\n",
            "Epoch 274/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5696 - val_accuracy: 0.7073\n",
            "Epoch 275/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5580 - val_accuracy: 0.6992\n",
            "Epoch 276/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0022 - accuracy: 1.0000 - val_loss: 2.5665 - val_accuracy: 0.7073\n",
            "Epoch 277/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5899 - val_accuracy: 0.6992\n",
            "Epoch 278/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5892 - val_accuracy: 0.7073\n",
            "Epoch 279/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5951 - val_accuracy: 0.7154\n",
            "Epoch 280/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.5850 - val_accuracy: 0.7073\n",
            "Epoch 281/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6010 - val_accuracy: 0.7073\n",
            "Epoch 282/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0021 - accuracy: 1.0000 - val_loss: 2.6126 - val_accuracy: 0.6992\n",
            "Epoch 283/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5734 - val_accuracy: 0.7154\n",
            "Epoch 284/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6321 - val_accuracy: 0.7073\n",
            "Epoch 285/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6047 - val_accuracy: 0.7073\n",
            "Epoch 286/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.5989 - val_accuracy: 0.7073\n",
            "Epoch 287/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6122 - val_accuracy: 0.7073\n",
            "Epoch 288/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6233 - val_accuracy: 0.6992\n",
            "Epoch 289/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6402 - val_accuracy: 0.6911\n",
            "Epoch 290/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6386 - val_accuracy: 0.6992\n",
            "Epoch 291/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0020 - accuracy: 1.0000 - val_loss: 2.6383 - val_accuracy: 0.7073\n",
            "Epoch 292/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6343 - val_accuracy: 0.7073\n",
            "Epoch 293/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6310 - val_accuracy: 0.6992\n",
            "Epoch 294/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6338 - val_accuracy: 0.6992\n",
            "Epoch 295/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6083 - val_accuracy: 0.6992\n",
            "Epoch 296/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0019 - accuracy: 1.0000 - val_loss: 2.6477 - val_accuracy: 0.6992\n",
            "Epoch 297/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6550 - val_accuracy: 0.7073\n",
            "Epoch 298/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6537 - val_accuracy: 0.6992\n",
            "Epoch 299/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6347 - val_accuracy: 0.6992\n",
            "Epoch 300/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6541 - val_accuracy: 0.7073\n",
            "Epoch 301/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6543 - val_accuracy: 0.7073\n",
            "Epoch 302/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6599 - val_accuracy: 0.6992\n",
            "Epoch 303/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6546 - val_accuracy: 0.7073\n",
            "Epoch 304/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6649 - val_accuracy: 0.6911\n",
            "Epoch 305/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0018 - accuracy: 1.0000 - val_loss: 2.6554 - val_accuracy: 0.6992\n",
            "Epoch 306/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6661 - val_accuracy: 0.7073\n",
            "Epoch 307/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6726 - val_accuracy: 0.7073\n",
            "Epoch 308/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6795 - val_accuracy: 0.7073\n",
            "Epoch 309/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6486 - val_accuracy: 0.7073\n",
            "Epoch 310/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6668 - val_accuracy: 0.6992\n",
            "Epoch 311/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6659 - val_accuracy: 0.6992\n",
            "Epoch 312/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6667 - val_accuracy: 0.7073\n",
            "Epoch 313/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6891 - val_accuracy: 0.6992\n",
            "Epoch 314/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6688 - val_accuracy: 0.7073\n",
            "Epoch 315/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6977 - val_accuracy: 0.7073\n",
            "Epoch 316/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0017 - accuracy: 1.0000 - val_loss: 2.6862 - val_accuracy: 0.7073\n",
            "Epoch 317/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6712 - val_accuracy: 0.7073\n",
            "Epoch 318/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6883 - val_accuracy: 0.6992\n",
            "Epoch 319/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6934 - val_accuracy: 0.7073\n",
            "Epoch 320/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6900 - val_accuracy: 0.7073\n",
            "Epoch 321/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.7027 - val_accuracy: 0.6992\n",
            "Epoch 322/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6984 - val_accuracy: 0.7073\n",
            "Epoch 323/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6938 - val_accuracy: 0.6992\n",
            "Epoch 324/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.6886 - val_accuracy: 0.6992\n",
            "Epoch 325/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.6978 - val_accuracy: 0.6992\n",
            "Epoch 326/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7039 - val_accuracy: 0.7073\n",
            "Epoch 327/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0016 - accuracy: 1.0000 - val_loss: 2.7117 - val_accuracy: 0.6992\n",
            "Epoch 328/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7144 - val_accuracy: 0.6992\n",
            "Epoch 329/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7248 - val_accuracy: 0.7073\n",
            "Epoch 330/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7205 - val_accuracy: 0.7073\n",
            "Epoch 331/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7178 - val_accuracy: 0.6992\n",
            "Epoch 332/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7167 - val_accuracy: 0.7073\n",
            "Epoch 333/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7249 - val_accuracy: 0.7073\n",
            "Epoch 334/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7294 - val_accuracy: 0.7073\n",
            "Epoch 335/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7043 - val_accuracy: 0.6992\n",
            "Epoch 336/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7274 - val_accuracy: 0.6992\n",
            "Epoch 337/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7273 - val_accuracy: 0.7073\n",
            "Epoch 338/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7344 - val_accuracy: 0.6992\n",
            "Epoch 339/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7181 - val_accuracy: 0.7073\n",
            "Epoch 340/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0015 - accuracy: 1.0000 - val_loss: 2.7294 - val_accuracy: 0.6992\n",
            "Epoch 341/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7419 - val_accuracy: 0.7073\n",
            "Epoch 342/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7412 - val_accuracy: 0.7073\n",
            "Epoch 343/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7340 - val_accuracy: 0.6992\n",
            "Epoch 344/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7479 - val_accuracy: 0.6992\n",
            "Epoch 345/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7427 - val_accuracy: 0.7073\n",
            "Epoch 346/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7386 - val_accuracy: 0.7073\n",
            "Epoch 347/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7519 - val_accuracy: 0.7073\n",
            "Epoch 348/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7568 - val_accuracy: 0.7073\n",
            "Epoch 349/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7434 - val_accuracy: 0.7073\n",
            "Epoch 350/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7513 - val_accuracy: 0.6992\n",
            "Epoch 351/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7597 - val_accuracy: 0.6992\n",
            "Epoch 352/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7619 - val_accuracy: 0.6992\n",
            "Epoch 353/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0014 - accuracy: 1.0000 - val_loss: 2.7518 - val_accuracy: 0.6992\n",
            "Epoch 354/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7580 - val_accuracy: 0.6992\n",
            "Epoch 355/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7519 - val_accuracy: 0.6992\n",
            "Epoch 356/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7758 - val_accuracy: 0.7154\n",
            "Epoch 357/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7608 - val_accuracy: 0.6992\n",
            "Epoch 358/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7617 - val_accuracy: 0.6992\n",
            "Epoch 359/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7652 - val_accuracy: 0.7073\n",
            "Epoch 360/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7783 - val_accuracy: 0.7154\n",
            "Epoch 361/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7745 - val_accuracy: 0.7073\n",
            "Epoch 362/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7793 - val_accuracy: 0.7073\n",
            "Epoch 363/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7618 - val_accuracy: 0.7073\n",
            "Epoch 364/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7792 - val_accuracy: 0.6992\n",
            "Epoch 365/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7938 - val_accuracy: 0.7073\n",
            "Epoch 366/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7736 - val_accuracy: 0.6992\n",
            "Epoch 367/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0013 - accuracy: 1.0000 - val_loss: 2.7869 - val_accuracy: 0.7073\n",
            "Epoch 368/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7872 - val_accuracy: 0.7073\n",
            "Epoch 369/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7888 - val_accuracy: 0.7073\n",
            "Epoch 370/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7951 - val_accuracy: 0.7073\n",
            "Epoch 371/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7984 - val_accuracy: 0.6992\n",
            "Epoch 372/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8073 - val_accuracy: 0.7073\n",
            "Epoch 373/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8103 - val_accuracy: 0.6992\n",
            "Epoch 374/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8109 - val_accuracy: 0.6992\n",
            "Epoch 375/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8019 - val_accuracy: 0.7073\n",
            "Epoch 376/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8033 - val_accuracy: 0.6992\n",
            "Epoch 377/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.7997 - val_accuracy: 0.6992\n",
            "Epoch 378/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8162 - val_accuracy: 0.7073\n",
            "Epoch 379/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8077 - val_accuracy: 0.7073\n",
            "Epoch 380/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8181 - val_accuracy: 0.6992\n",
            "Epoch 381/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8078 - val_accuracy: 0.6992\n",
            "Epoch 382/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8078 - val_accuracy: 0.7073\n",
            "Epoch 383/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8271 - val_accuracy: 0.7154\n",
            "Epoch 384/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8240 - val_accuracy: 0.7073\n",
            "Epoch 385/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8237 - val_accuracy: 0.7073\n",
            "Epoch 386/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0012 - accuracy: 1.0000 - val_loss: 2.8210 - val_accuracy: 0.6992\n",
            "Epoch 387/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8340 - val_accuracy: 0.6992\n",
            "Epoch 388/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8273 - val_accuracy: 0.6992\n",
            "Epoch 389/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8341 - val_accuracy: 0.7073\n",
            "Epoch 390/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8344 - val_accuracy: 0.7073\n",
            "Epoch 391/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8320 - val_accuracy: 0.7073\n",
            "Epoch 392/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8304 - val_accuracy: 0.6992\n",
            "Epoch 393/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8418 - val_accuracy: 0.7154\n",
            "Epoch 394/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8354 - val_accuracy: 0.6992\n",
            "Epoch 395/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8238 - val_accuracy: 0.6992\n",
            "Epoch 396/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8407 - val_accuracy: 0.7073\n",
            "Epoch 397/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8291 - val_accuracy: 0.7073\n",
            "Epoch 398/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8453 - val_accuracy: 0.6992\n",
            "Epoch 399/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8435 - val_accuracy: 0.6992\n",
            "Epoch 400/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8327 - val_accuracy: 0.6992\n",
            "Epoch 401/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8528 - val_accuracy: 0.6992\n",
            "Epoch 402/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8356 - val_accuracy: 0.6992\n",
            "Epoch 403/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8448 - val_accuracy: 0.6992\n",
            "Epoch 404/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8404 - val_accuracy: 0.6992\n",
            "Epoch 405/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8427 - val_accuracy: 0.6992\n",
            "Epoch 406/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8604 - val_accuracy: 0.7073\n",
            "Epoch 407/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8572 - val_accuracy: 0.6992\n",
            "Epoch 408/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0011 - accuracy: 1.0000 - val_loss: 2.8484 - val_accuracy: 0.6992\n",
            "Epoch 409/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8575 - val_accuracy: 0.7073\n",
            "Epoch 410/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8584 - val_accuracy: 0.6992\n",
            "Epoch 411/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8709 - val_accuracy: 0.7073\n",
            "Epoch 412/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8702 - val_accuracy: 0.6992\n",
            "Epoch 413/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8706 - val_accuracy: 0.6992\n",
            "Epoch 414/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8675 - val_accuracy: 0.6992\n",
            "Epoch 415/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8685 - val_accuracy: 0.7073\n",
            "Epoch 416/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8714 - val_accuracy: 0.6992\n",
            "Epoch 417/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8707 - val_accuracy: 0.6992\n",
            "Epoch 418/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.9711e-04 - accuracy: 1.0000 - val_loss: 2.8700 - val_accuracy: 0.6992\n",
            "Epoch 419/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 0.0010 - accuracy: 1.0000 - val_loss: 2.8647 - val_accuracy: 0.6992\n",
            "Epoch 420/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.8929e-04 - accuracy: 1.0000 - val_loss: 2.8702 - val_accuracy: 0.6992\n",
            "Epoch 421/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.9338e-04 - accuracy: 1.0000 - val_loss: 2.8714 - val_accuracy: 0.6992\n",
            "Epoch 422/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.8606e-04 - accuracy: 1.0000 - val_loss: 2.8738 - val_accuracy: 0.7073\n",
            "Epoch 423/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.8322e-04 - accuracy: 1.0000 - val_loss: 2.8814 - val_accuracy: 0.7073\n",
            "Epoch 424/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.7982e-04 - accuracy: 1.0000 - val_loss: 2.8875 - val_accuracy: 0.6992\n",
            "Epoch 425/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.6895e-04 - accuracy: 1.0000 - val_loss: 2.8974 - val_accuracy: 0.6992\n",
            "Epoch 426/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.8335e-04 - accuracy: 1.0000 - val_loss: 2.8939 - val_accuracy: 0.6992\n",
            "Epoch 427/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.5809e-04 - accuracy: 1.0000 - val_loss: 2.8939 - val_accuracy: 0.7073\n",
            "Epoch 428/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.6733e-04 - accuracy: 1.0000 - val_loss: 2.8903 - val_accuracy: 0.6992\n",
            "Epoch 429/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.4044e-04 - accuracy: 1.0000 - val_loss: 2.8937 - val_accuracy: 0.6992\n",
            "Epoch 430/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.6833e-04 - accuracy: 1.0000 - val_loss: 2.8889 - val_accuracy: 0.6992\n",
            "Epoch 431/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.4563e-04 - accuracy: 1.0000 - val_loss: 2.8970 - val_accuracy: 0.6992\n",
            "Epoch 432/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.5380e-04 - accuracy: 1.0000 - val_loss: 2.8953 - val_accuracy: 0.6992\n",
            "Epoch 433/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.4915e-04 - accuracy: 1.0000 - val_loss: 2.8977 - val_accuracy: 0.6992\n",
            "Epoch 434/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.4802e-04 - accuracy: 1.0000 - val_loss: 2.8915 - val_accuracy: 0.6992\n",
            "Epoch 435/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.4319e-04 - accuracy: 1.0000 - val_loss: 2.8980 - val_accuracy: 0.6992\n",
            "Epoch 436/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.2440e-04 - accuracy: 1.0000 - val_loss: 2.8989 - val_accuracy: 0.6992\n",
            "Epoch 437/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.3403e-04 - accuracy: 1.0000 - val_loss: 2.9005 - val_accuracy: 0.7073\n",
            "Epoch 438/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.3073e-04 - accuracy: 1.0000 - val_loss: 2.9043 - val_accuracy: 0.7073\n",
            "Epoch 439/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.3405e-04 - accuracy: 1.0000 - val_loss: 2.9050 - val_accuracy: 0.6992\n",
            "Epoch 440/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.2164e-04 - accuracy: 1.0000 - val_loss: 2.9003 - val_accuracy: 0.6992\n",
            "Epoch 441/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.2346e-04 - accuracy: 1.0000 - val_loss: 2.9065 - val_accuracy: 0.6992\n",
            "Epoch 442/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.1691e-04 - accuracy: 1.0000 - val_loss: 2.9075 - val_accuracy: 0.6992\n",
            "Epoch 443/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.2110e-04 - accuracy: 1.0000 - val_loss: 2.9132 - val_accuracy: 0.6992\n",
            "Epoch 444/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.0621e-04 - accuracy: 1.0000 - val_loss: 2.8983 - val_accuracy: 0.6992\n",
            "Epoch 445/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.0589e-04 - accuracy: 1.0000 - val_loss: 2.9204 - val_accuracy: 0.7073\n",
            "Epoch 446/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.0491e-04 - accuracy: 1.0000 - val_loss: 2.9076 - val_accuracy: 0.6992\n",
            "Epoch 447/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.9730e-04 - accuracy: 1.0000 - val_loss: 2.9211 - val_accuracy: 0.6992\n",
            "Epoch 448/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.9918e-04 - accuracy: 1.0000 - val_loss: 2.9152 - val_accuracy: 0.6992\n",
            "Epoch 449/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.7857e-04 - accuracy: 1.0000 - val_loss: 2.9236 - val_accuracy: 0.6992\n",
            "Epoch 450/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 9.1092e-04 - accuracy: 1.0000 - val_loss: 2.9257 - val_accuracy: 0.6992\n",
            "Epoch 451/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.8265e-04 - accuracy: 1.0000 - val_loss: 2.9217 - val_accuracy: 0.6992\n",
            "Epoch 452/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.8406e-04 - accuracy: 1.0000 - val_loss: 2.9222 - val_accuracy: 0.6992\n",
            "Epoch 453/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.6888e-04 - accuracy: 1.0000 - val_loss: 2.9298 - val_accuracy: 0.7073\n",
            "Epoch 454/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.8123e-04 - accuracy: 1.0000 - val_loss: 2.9200 - val_accuracy: 0.6992\n",
            "Epoch 455/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.7460e-04 - accuracy: 1.0000 - val_loss: 2.9298 - val_accuracy: 0.6992\n",
            "Epoch 456/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.6864e-04 - accuracy: 1.0000 - val_loss: 2.9222 - val_accuracy: 0.6992\n",
            "Epoch 457/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.6487e-04 - accuracy: 1.0000 - val_loss: 2.9281 - val_accuracy: 0.6992\n",
            "Epoch 458/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.5552e-04 - accuracy: 1.0000 - val_loss: 2.9337 - val_accuracy: 0.7073\n",
            "Epoch 459/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.6599e-04 - accuracy: 1.0000 - val_loss: 2.9325 - val_accuracy: 0.6992\n",
            "Epoch 460/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.5326e-04 - accuracy: 1.0000 - val_loss: 2.9264 - val_accuracy: 0.6992\n",
            "Epoch 461/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.6446e-04 - accuracy: 1.0000 - val_loss: 2.9331 - val_accuracy: 0.6992\n",
            "Epoch 462/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.5161e-04 - accuracy: 1.0000 - val_loss: 2.9364 - val_accuracy: 0.6992\n",
            "Epoch 463/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.4991e-04 - accuracy: 1.0000 - val_loss: 2.9351 - val_accuracy: 0.6992\n",
            "Epoch 464/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.3811e-04 - accuracy: 1.0000 - val_loss: 2.9493 - val_accuracy: 0.6992\n",
            "Epoch 465/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.4292e-04 - accuracy: 1.0000 - val_loss: 2.9410 - val_accuracy: 0.6992\n",
            "Epoch 466/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.3492e-04 - accuracy: 1.0000 - val_loss: 2.9418 - val_accuracy: 0.6992\n",
            "Epoch 467/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.4096e-04 - accuracy: 1.0000 - val_loss: 2.9452 - val_accuracy: 0.6992\n",
            "Epoch 468/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.3550e-04 - accuracy: 1.0000 - val_loss: 2.9421 - val_accuracy: 0.6992\n",
            "Epoch 469/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.2687e-04 - accuracy: 1.0000 - val_loss: 2.9421 - val_accuracy: 0.6992\n",
            "Epoch 470/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.1725e-04 - accuracy: 1.0000 - val_loss: 2.9516 - val_accuracy: 0.7073\n",
            "Epoch 471/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.3551e-04 - accuracy: 1.0000 - val_loss: 2.9488 - val_accuracy: 0.6992\n",
            "Epoch 472/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.2909e-04 - accuracy: 1.0000 - val_loss: 2.9514 - val_accuracy: 0.6992\n",
            "Epoch 473/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.2136e-04 - accuracy: 1.0000 - val_loss: 2.9525 - val_accuracy: 0.6992\n",
            "Epoch 474/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.1747e-04 - accuracy: 1.0000 - val_loss: 2.9466 - val_accuracy: 0.6992\n",
            "Epoch 475/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.1590e-04 - accuracy: 1.0000 - val_loss: 2.9523 - val_accuracy: 0.6992\n",
            "Epoch 476/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.9584e-04 - accuracy: 1.0000 - val_loss: 2.9536 - val_accuracy: 0.6992\n",
            "Epoch 477/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.1603e-04 - accuracy: 1.0000 - val_loss: 2.9558 - val_accuracy: 0.6992\n",
            "Epoch 478/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.0710e-04 - accuracy: 1.0000 - val_loss: 2.9589 - val_accuracy: 0.6992\n",
            "Epoch 479/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.0762e-04 - accuracy: 1.0000 - val_loss: 2.9546 - val_accuracy: 0.6992\n",
            "Epoch 480/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.0091e-04 - accuracy: 1.0000 - val_loss: 2.9654 - val_accuracy: 0.6992\n",
            "Epoch 481/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.9651e-04 - accuracy: 1.0000 - val_loss: 2.9638 - val_accuracy: 0.6992\n",
            "Epoch 482/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 8.0388e-04 - accuracy: 1.0000 - val_loss: 2.9598 - val_accuracy: 0.6992\n",
            "Epoch 483/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.8612e-04 - accuracy: 1.0000 - val_loss: 2.9755 - val_accuracy: 0.6992\n",
            "Epoch 484/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.8910e-04 - accuracy: 1.0000 - val_loss: 2.9687 - val_accuracy: 0.6911\n",
            "Epoch 485/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.8765e-04 - accuracy: 1.0000 - val_loss: 2.9700 - val_accuracy: 0.6992\n",
            "Epoch 486/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.7790e-04 - accuracy: 1.0000 - val_loss: 2.9645 - val_accuracy: 0.6992\n",
            "Epoch 487/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.8878e-04 - accuracy: 1.0000 - val_loss: 2.9697 - val_accuracy: 0.6992\n",
            "Epoch 488/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.6714e-04 - accuracy: 1.0000 - val_loss: 2.9757 - val_accuracy: 0.6992\n",
            "Epoch 489/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.7558e-04 - accuracy: 1.0000 - val_loss: 2.9715 - val_accuracy: 0.6992\n",
            "Epoch 490/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.6666e-04 - accuracy: 1.0000 - val_loss: 2.9703 - val_accuracy: 0.6992\n",
            "Epoch 491/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.7245e-04 - accuracy: 1.0000 - val_loss: 2.9737 - val_accuracy: 0.6992\n",
            "Epoch 492/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.6117e-04 - accuracy: 1.0000 - val_loss: 2.9742 - val_accuracy: 0.6992\n",
            "Epoch 493/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.5786e-04 - accuracy: 1.0000 - val_loss: 2.9837 - val_accuracy: 0.6992\n",
            "Epoch 494/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.6933e-04 - accuracy: 1.0000 - val_loss: 2.9743 - val_accuracy: 0.6992\n",
            "Epoch 495/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.6522e-04 - accuracy: 1.0000 - val_loss: 2.9715 - val_accuracy: 0.6992\n",
            "Epoch 496/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.6146e-04 - accuracy: 1.0000 - val_loss: 2.9850 - val_accuracy: 0.6992\n",
            "Epoch 497/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.5031e-04 - accuracy: 1.0000 - val_loss: 2.9865 - val_accuracy: 0.6992\n",
            "Epoch 498/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.5726e-04 - accuracy: 1.0000 - val_loss: 2.9866 - val_accuracy: 0.6992\n",
            "Epoch 499/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.5658e-04 - accuracy: 1.0000 - val_loss: 2.9842 - val_accuracy: 0.6992\n",
            "Epoch 500/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.4784e-04 - accuracy: 1.0000 - val_loss: 2.9818 - val_accuracy: 0.6992\n",
            "Epoch 501/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.5366e-04 - accuracy: 1.0000 - val_loss: 2.9819 - val_accuracy: 0.6992\n",
            "Epoch 502/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.2657e-04 - accuracy: 1.0000 - val_loss: 2.9870 - val_accuracy: 0.6911\n",
            "Epoch 503/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.4307e-04 - accuracy: 1.0000 - val_loss: 2.9854 - val_accuracy: 0.6992\n",
            "Epoch 504/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.4650e-04 - accuracy: 1.0000 - val_loss: 2.9876 - val_accuracy: 0.6992\n",
            "Epoch 505/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.3594e-04 - accuracy: 1.0000 - val_loss: 2.9852 - val_accuracy: 0.6992\n",
            "Epoch 506/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.3183e-04 - accuracy: 1.0000 - val_loss: 2.9874 - val_accuracy: 0.6992\n",
            "Epoch 507/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.3917e-04 - accuracy: 1.0000 - val_loss: 2.9898 - val_accuracy: 0.6992\n",
            "Epoch 508/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.3617e-04 - accuracy: 1.0000 - val_loss: 2.9963 - val_accuracy: 0.6992\n",
            "Epoch 509/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.2581e-04 - accuracy: 1.0000 - val_loss: 2.9987 - val_accuracy: 0.6992\n",
            "Epoch 510/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.3063e-04 - accuracy: 1.0000 - val_loss: 2.9954 - val_accuracy: 0.6992\n",
            "Epoch 511/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.1669e-04 - accuracy: 1.0000 - val_loss: 2.9961 - val_accuracy: 0.6992\n",
            "Epoch 512/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.3396e-04 - accuracy: 1.0000 - val_loss: 3.0042 - val_accuracy: 0.6992\n",
            "Epoch 513/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.2050e-04 - accuracy: 1.0000 - val_loss: 3.0048 - val_accuracy: 0.6992\n",
            "Epoch 514/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.2153e-04 - accuracy: 1.0000 - val_loss: 3.0015 - val_accuracy: 0.6992\n",
            "Epoch 515/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.1749e-04 - accuracy: 1.0000 - val_loss: 3.0041 - val_accuracy: 0.6992\n",
            "Epoch 516/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.1130e-04 - accuracy: 1.0000 - val_loss: 3.0017 - val_accuracy: 0.6992\n",
            "Epoch 517/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.1422e-04 - accuracy: 1.0000 - val_loss: 3.0079 - val_accuracy: 0.6992\n",
            "Epoch 518/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.1264e-04 - accuracy: 1.0000 - val_loss: 3.0111 - val_accuracy: 0.6992\n",
            "Epoch 519/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.1070e-04 - accuracy: 1.0000 - val_loss: 3.0060 - val_accuracy: 0.6992\n",
            "Epoch 520/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.0576e-04 - accuracy: 1.0000 - val_loss: 3.0129 - val_accuracy: 0.6992\n",
            "Epoch 521/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.1131e-04 - accuracy: 1.0000 - val_loss: 3.0082 - val_accuracy: 0.6992\n",
            "Epoch 522/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 7.0182e-04 - accuracy: 1.0000 - val_loss: 3.0125 - val_accuracy: 0.6992\n",
            "Epoch 523/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.9873e-04 - accuracy: 1.0000 - val_loss: 3.0175 - val_accuracy: 0.6992\n",
            "Epoch 524/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.8746e-04 - accuracy: 1.0000 - val_loss: 3.0148 - val_accuracy: 0.6992\n",
            "Epoch 525/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.9789e-04 - accuracy: 1.0000 - val_loss: 3.0171 - val_accuracy: 0.6992\n",
            "Epoch 526/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.9397e-04 - accuracy: 1.0000 - val_loss: 3.0094 - val_accuracy: 0.6992\n",
            "Epoch 527/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.9276e-04 - accuracy: 1.0000 - val_loss: 3.0125 - val_accuracy: 0.6992\n",
            "Epoch 528/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.8962e-04 - accuracy: 1.0000 - val_loss: 3.0212 - val_accuracy: 0.6992\n",
            "Epoch 529/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.8950e-04 - accuracy: 1.0000 - val_loss: 3.0176 - val_accuracy: 0.6992\n",
            "Epoch 530/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.8976e-04 - accuracy: 1.0000 - val_loss: 3.0253 - val_accuracy: 0.6992\n",
            "Epoch 531/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.8461e-04 - accuracy: 1.0000 - val_loss: 3.0256 - val_accuracy: 0.6992\n",
            "Epoch 532/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.8281e-04 - accuracy: 1.0000 - val_loss: 3.0272 - val_accuracy: 0.6992\n",
            "Epoch 533/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.7843e-04 - accuracy: 1.0000 - val_loss: 3.0275 - val_accuracy: 0.6992\n",
            "Epoch 534/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.7939e-04 - accuracy: 1.0000 - val_loss: 3.0279 - val_accuracy: 0.6992\n",
            "Epoch 535/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.7629e-04 - accuracy: 1.0000 - val_loss: 3.0339 - val_accuracy: 0.6992\n",
            "Epoch 536/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.7561e-04 - accuracy: 1.0000 - val_loss: 3.0343 - val_accuracy: 0.6992\n",
            "Epoch 537/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.6809e-04 - accuracy: 1.0000 - val_loss: 3.0282 - val_accuracy: 0.6992\n",
            "Epoch 538/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.6936e-04 - accuracy: 1.0000 - val_loss: 3.0368 - val_accuracy: 0.6992\n",
            "Epoch 539/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.6876e-04 - accuracy: 1.0000 - val_loss: 3.0304 - val_accuracy: 0.6992\n",
            "Epoch 540/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.6516e-04 - accuracy: 1.0000 - val_loss: 3.0371 - val_accuracy: 0.6992\n",
            "Epoch 541/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.6899e-04 - accuracy: 1.0000 - val_loss: 3.0341 - val_accuracy: 0.6992\n",
            "Epoch 542/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.5222e-04 - accuracy: 1.0000 - val_loss: 3.0300 - val_accuracy: 0.6992\n",
            "Epoch 543/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.6351e-04 - accuracy: 1.0000 - val_loss: 3.0374 - val_accuracy: 0.6992\n",
            "Epoch 544/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.5083e-04 - accuracy: 1.0000 - val_loss: 3.0385 - val_accuracy: 0.6992\n",
            "Epoch 545/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.5905e-04 - accuracy: 1.0000 - val_loss: 3.0465 - val_accuracy: 0.6992\n",
            "Epoch 546/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.5707e-04 - accuracy: 1.0000 - val_loss: 3.0419 - val_accuracy: 0.6992\n",
            "Epoch 547/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.4831e-04 - accuracy: 1.0000 - val_loss: 3.0458 - val_accuracy: 0.6992\n",
            "Epoch 548/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.5244e-04 - accuracy: 1.0000 - val_loss: 3.0365 - val_accuracy: 0.6992\n",
            "Epoch 549/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.5168e-04 - accuracy: 1.0000 - val_loss: 3.0441 - val_accuracy: 0.6992\n",
            "Epoch 550/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.4915e-04 - accuracy: 1.0000 - val_loss: 3.0430 - val_accuracy: 0.6992\n",
            "Epoch 551/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.4751e-04 - accuracy: 1.0000 - val_loss: 3.0449 - val_accuracy: 0.6992\n",
            "Epoch 552/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.4235e-04 - accuracy: 1.0000 - val_loss: 3.0456 - val_accuracy: 0.6992\n",
            "Epoch 553/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.3877e-04 - accuracy: 1.0000 - val_loss: 3.0463 - val_accuracy: 0.6992\n",
            "Epoch 554/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.4151e-04 - accuracy: 1.0000 - val_loss: 3.0466 - val_accuracy: 0.6992\n",
            "Epoch 555/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.4045e-04 - accuracy: 1.0000 - val_loss: 3.0512 - val_accuracy: 0.6992\n",
            "Epoch 556/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.3664e-04 - accuracy: 1.0000 - val_loss: 3.0497 - val_accuracy: 0.6992\n",
            "Epoch 557/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.3671e-04 - accuracy: 1.0000 - val_loss: 3.0558 - val_accuracy: 0.6992\n",
            "Epoch 558/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.3253e-04 - accuracy: 1.0000 - val_loss: 3.0494 - val_accuracy: 0.6992\n",
            "Epoch 559/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.3384e-04 - accuracy: 1.0000 - val_loss: 3.0567 - val_accuracy: 0.6992\n",
            "Epoch 560/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.3257e-04 - accuracy: 1.0000 - val_loss: 3.0526 - val_accuracy: 0.6992\n",
            "Epoch 561/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.3691e-04 - accuracy: 1.0000 - val_loss: 3.0549 - val_accuracy: 0.6992\n",
            "Epoch 562/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.2602e-04 - accuracy: 1.0000 - val_loss: 3.0647 - val_accuracy: 0.6992\n",
            "Epoch 563/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.2499e-04 - accuracy: 1.0000 - val_loss: 3.0527 - val_accuracy: 0.6992\n",
            "Epoch 564/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.2745e-04 - accuracy: 1.0000 - val_loss: 3.0577 - val_accuracy: 0.6992\n",
            "Epoch 565/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.2321e-04 - accuracy: 1.0000 - val_loss: 3.0608 - val_accuracy: 0.6992\n",
            "Epoch 566/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.0884e-04 - accuracy: 1.0000 - val_loss: 3.0603 - val_accuracy: 0.6992\n",
            "Epoch 567/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.1914e-04 - accuracy: 1.0000 - val_loss: 3.0585 - val_accuracy: 0.6992\n",
            "Epoch 568/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.2007e-04 - accuracy: 1.0000 - val_loss: 3.0659 - val_accuracy: 0.6992\n",
            "Epoch 569/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.1477e-04 - accuracy: 1.0000 - val_loss: 3.0684 - val_accuracy: 0.6992\n",
            "Epoch 570/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.1432e-04 - accuracy: 1.0000 - val_loss: 3.0674 - val_accuracy: 0.6992\n",
            "Epoch 571/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.1816e-04 - accuracy: 1.0000 - val_loss: 3.0668 - val_accuracy: 0.6992\n",
            "Epoch 572/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.0717e-04 - accuracy: 1.0000 - val_loss: 3.0674 - val_accuracy: 0.6992\n",
            "Epoch 573/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.1198e-04 - accuracy: 1.0000 - val_loss: 3.0717 - val_accuracy: 0.6992\n",
            "Epoch 574/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.0779e-04 - accuracy: 1.0000 - val_loss: 3.0670 - val_accuracy: 0.6992\n",
            "Epoch 575/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.0996e-04 - accuracy: 1.0000 - val_loss: 3.0746 - val_accuracy: 0.6992\n",
            "Epoch 576/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.0063e-04 - accuracy: 1.0000 - val_loss: 3.0689 - val_accuracy: 0.6992\n",
            "Epoch 577/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.0641e-04 - accuracy: 1.0000 - val_loss: 3.0680 - val_accuracy: 0.6992\n",
            "Epoch 578/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.9971e-04 - accuracy: 1.0000 - val_loss: 3.0734 - val_accuracy: 0.6992\n",
            "Epoch 579/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.9960e-04 - accuracy: 1.0000 - val_loss: 3.0802 - val_accuracy: 0.6992\n",
            "Epoch 580/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 6.0093e-04 - accuracy: 1.0000 - val_loss: 3.0771 - val_accuracy: 0.6992\n",
            "Epoch 581/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.9531e-04 - accuracy: 1.0000 - val_loss: 3.0764 - val_accuracy: 0.6992\n",
            "Epoch 582/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.9620e-04 - accuracy: 1.0000 - val_loss: 3.0736 - val_accuracy: 0.6992\n",
            "Epoch 583/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.9852e-04 - accuracy: 1.0000 - val_loss: 3.0776 - val_accuracy: 0.6992\n",
            "Epoch 584/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.9185e-04 - accuracy: 1.0000 - val_loss: 3.0782 - val_accuracy: 0.6992\n",
            "Epoch 585/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.9135e-04 - accuracy: 1.0000 - val_loss: 3.0789 - val_accuracy: 0.6992\n",
            "Epoch 586/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.8469e-04 - accuracy: 1.0000 - val_loss: 3.0777 - val_accuracy: 0.6992\n",
            "Epoch 587/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.8230e-04 - accuracy: 1.0000 - val_loss: 3.0797 - val_accuracy: 0.6992\n",
            "Epoch 588/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.8913e-04 - accuracy: 1.0000 - val_loss: 3.0812 - val_accuracy: 0.6992\n",
            "Epoch 589/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.8271e-04 - accuracy: 1.0000 - val_loss: 3.0799 - val_accuracy: 0.6992\n",
            "Epoch 590/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.8163e-04 - accuracy: 1.0000 - val_loss: 3.0847 - val_accuracy: 0.6992\n",
            "Epoch 591/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7560e-04 - accuracy: 1.0000 - val_loss: 3.0822 - val_accuracy: 0.6992\n",
            "Epoch 592/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.8211e-04 - accuracy: 1.0000 - val_loss: 3.0870 - val_accuracy: 0.6992\n",
            "Epoch 593/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7682e-04 - accuracy: 1.0000 - val_loss: 3.0854 - val_accuracy: 0.6992\n",
            "Epoch 594/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7337e-04 - accuracy: 1.0000 - val_loss: 3.0863 - val_accuracy: 0.6992\n",
            "Epoch 595/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7249e-04 - accuracy: 1.0000 - val_loss: 3.0909 - val_accuracy: 0.6992\n",
            "Epoch 596/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7200e-04 - accuracy: 1.0000 - val_loss: 3.0881 - val_accuracy: 0.6992\n",
            "Epoch 597/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7055e-04 - accuracy: 1.0000 - val_loss: 3.0972 - val_accuracy: 0.6992\n",
            "Epoch 598/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7155e-04 - accuracy: 1.0000 - val_loss: 3.0961 - val_accuracy: 0.6992\n",
            "Epoch 599/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.6946e-04 - accuracy: 1.0000 - val_loss: 3.0977 - val_accuracy: 0.6992\n",
            "Epoch 600/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.6565e-04 - accuracy: 1.0000 - val_loss: 3.0937 - val_accuracy: 0.6992\n",
            "Epoch 601/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.6299e-04 - accuracy: 1.0000 - val_loss: 3.0930 - val_accuracy: 0.6992\n",
            "Epoch 602/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.6523e-04 - accuracy: 1.0000 - val_loss: 3.0943 - val_accuracy: 0.6992\n",
            "Epoch 603/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.6522e-04 - accuracy: 1.0000 - val_loss: 3.1018 - val_accuracy: 0.6992\n",
            "Epoch 604/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.7120e-04 - accuracy: 1.0000 - val_loss: 3.0993 - val_accuracy: 0.6992\n",
            "Epoch 605/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5782e-04 - accuracy: 1.0000 - val_loss: 3.0993 - val_accuracy: 0.6992\n",
            "Epoch 606/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5600e-04 - accuracy: 1.0000 - val_loss: 3.0988 - val_accuracy: 0.6992\n",
            "Epoch 607/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5873e-04 - accuracy: 1.0000 - val_loss: 3.1060 - val_accuracy: 0.6992\n",
            "Epoch 608/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5334e-04 - accuracy: 1.0000 - val_loss: 3.1044 - val_accuracy: 0.6992\n",
            "Epoch 609/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5556e-04 - accuracy: 1.0000 - val_loss: 3.1067 - val_accuracy: 0.6992\n",
            "Epoch 610/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4950e-04 - accuracy: 1.0000 - val_loss: 3.1062 - val_accuracy: 0.6992\n",
            "Epoch 611/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5661e-04 - accuracy: 1.0000 - val_loss: 3.1075 - val_accuracy: 0.6992\n",
            "Epoch 612/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4822e-04 - accuracy: 1.0000 - val_loss: 3.1058 - val_accuracy: 0.6992\n",
            "Epoch 613/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5095e-04 - accuracy: 1.0000 - val_loss: 3.1118 - val_accuracy: 0.6992\n",
            "Epoch 614/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.5042e-04 - accuracy: 1.0000 - val_loss: 3.1089 - val_accuracy: 0.6992\n",
            "Epoch 615/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4478e-04 - accuracy: 1.0000 - val_loss: 3.1084 - val_accuracy: 0.6992\n",
            "Epoch 616/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4347e-04 - accuracy: 1.0000 - val_loss: 3.1128 - val_accuracy: 0.6992\n",
            "Epoch 617/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4219e-04 - accuracy: 1.0000 - val_loss: 3.1135 - val_accuracy: 0.6992\n",
            "Epoch 618/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4613e-04 - accuracy: 1.0000 - val_loss: 3.1139 - val_accuracy: 0.6992\n",
            "Epoch 619/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4307e-04 - accuracy: 1.0000 - val_loss: 3.1145 - val_accuracy: 0.6992\n",
            "Epoch 620/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4157e-04 - accuracy: 1.0000 - val_loss: 3.1177 - val_accuracy: 0.6992\n",
            "Epoch 621/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.3751e-04 - accuracy: 1.0000 - val_loss: 3.1174 - val_accuracy: 0.6992\n",
            "Epoch 622/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.3326e-04 - accuracy: 1.0000 - val_loss: 3.1173 - val_accuracy: 0.6992\n",
            "Epoch 623/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.4060e-04 - accuracy: 1.0000 - val_loss: 3.1171 - val_accuracy: 0.6992\n",
            "Epoch 624/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.3367e-04 - accuracy: 1.0000 - val_loss: 3.1178 - val_accuracy: 0.6992\n",
            "Epoch 625/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2938e-04 - accuracy: 1.0000 - val_loss: 3.1211 - val_accuracy: 0.6992\n",
            "Epoch 626/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.3639e-04 - accuracy: 1.0000 - val_loss: 3.1162 - val_accuracy: 0.6992\n",
            "Epoch 627/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.3094e-04 - accuracy: 1.0000 - val_loss: 3.1182 - val_accuracy: 0.6992\n",
            "Epoch 628/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2965e-04 - accuracy: 1.0000 - val_loss: 3.1256 - val_accuracy: 0.6992\n",
            "Epoch 629/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2508e-04 - accuracy: 1.0000 - val_loss: 3.1240 - val_accuracy: 0.6992\n",
            "Epoch 630/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2373e-04 - accuracy: 1.0000 - val_loss: 3.1222 - val_accuracy: 0.6992\n",
            "Epoch 631/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2101e-04 - accuracy: 1.0000 - val_loss: 3.1232 - val_accuracy: 0.6992\n",
            "Epoch 632/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2550e-04 - accuracy: 1.0000 - val_loss: 3.1266 - val_accuracy: 0.6992\n",
            "Epoch 633/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2406e-04 - accuracy: 1.0000 - val_loss: 3.1321 - val_accuracy: 0.6992\n",
            "Epoch 634/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.1960e-04 - accuracy: 1.0000 - val_loss: 3.1303 - val_accuracy: 0.6992\n",
            "Epoch 635/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2053e-04 - accuracy: 1.0000 - val_loss: 3.1290 - val_accuracy: 0.6992\n",
            "Epoch 636/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2036e-04 - accuracy: 1.0000 - val_loss: 3.1242 - val_accuracy: 0.6992\n",
            "Epoch 637/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.2260e-04 - accuracy: 1.0000 - val_loss: 3.1290 - val_accuracy: 0.6992\n",
            "Epoch 638/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.1615e-04 - accuracy: 1.0000 - val_loss: 3.1321 - val_accuracy: 0.6992\n",
            "Epoch 639/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.1875e-04 - accuracy: 1.0000 - val_loss: 3.1278 - val_accuracy: 0.6992\n",
            "Epoch 640/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.1408e-04 - accuracy: 1.0000 - val_loss: 3.1380 - val_accuracy: 0.6992\n",
            "Epoch 641/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.1928e-04 - accuracy: 1.0000 - val_loss: 3.1364 - val_accuracy: 0.6992\n",
            "Epoch 642/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.1181e-04 - accuracy: 1.0000 - val_loss: 3.1361 - val_accuracy: 0.6992\n",
            "Epoch 643/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.1464e-04 - accuracy: 1.0000 - val_loss: 3.1382 - val_accuracy: 0.6992\n",
            "Epoch 644/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0818e-04 - accuracy: 1.0000 - val_loss: 3.1347 - val_accuracy: 0.6992\n",
            "Epoch 645/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0957e-04 - accuracy: 1.0000 - val_loss: 3.1407 - val_accuracy: 0.6992\n",
            "Epoch 646/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0552e-04 - accuracy: 1.0000 - val_loss: 3.1373 - val_accuracy: 0.6992\n",
            "Epoch 647/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0833e-04 - accuracy: 1.0000 - val_loss: 3.1443 - val_accuracy: 0.6992\n",
            "Epoch 648/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0341e-04 - accuracy: 1.0000 - val_loss: 3.1407 - val_accuracy: 0.6992\n",
            "Epoch 649/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0215e-04 - accuracy: 1.0000 - val_loss: 3.1430 - val_accuracy: 0.6992\n",
            "Epoch 650/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0413e-04 - accuracy: 1.0000 - val_loss: 3.1474 - val_accuracy: 0.6992\n",
            "Epoch 651/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9760e-04 - accuracy: 1.0000 - val_loss: 3.1473 - val_accuracy: 0.6992\n",
            "Epoch 652/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0109e-04 - accuracy: 1.0000 - val_loss: 3.1449 - val_accuracy: 0.6911\n",
            "Epoch 653/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 5.0626e-04 - accuracy: 1.0000 - val_loss: 3.1463 - val_accuracy: 0.6992\n",
            "Epoch 654/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9861e-04 - accuracy: 1.0000 - val_loss: 3.1509 - val_accuracy: 0.6992\n",
            "Epoch 655/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9626e-04 - accuracy: 1.0000 - val_loss: 3.1461 - val_accuracy: 0.6992\n",
            "Epoch 656/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9827e-04 - accuracy: 1.0000 - val_loss: 3.1451 - val_accuracy: 0.6992\n",
            "Epoch 657/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9663e-04 - accuracy: 1.0000 - val_loss: 3.1449 - val_accuracy: 0.6992\n",
            "Epoch 658/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9080e-04 - accuracy: 1.0000 - val_loss: 3.1502 - val_accuracy: 0.6911\n",
            "Epoch 659/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9316e-04 - accuracy: 1.0000 - val_loss: 3.1489 - val_accuracy: 0.6992\n",
            "Epoch 660/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9264e-04 - accuracy: 1.0000 - val_loss: 3.1513 - val_accuracy: 0.6992\n",
            "Epoch 661/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8730e-04 - accuracy: 1.0000 - val_loss: 3.1473 - val_accuracy: 0.6992\n",
            "Epoch 662/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.9200e-04 - accuracy: 1.0000 - val_loss: 3.1530 - val_accuracy: 0.6992\n",
            "Epoch 663/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8854e-04 - accuracy: 1.0000 - val_loss: 3.1555 - val_accuracy: 0.6992\n",
            "Epoch 664/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8830e-04 - accuracy: 1.0000 - val_loss: 3.1593 - val_accuracy: 0.6992\n",
            "Epoch 665/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8671e-04 - accuracy: 1.0000 - val_loss: 3.1595 - val_accuracy: 0.6992\n",
            "Epoch 666/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8440e-04 - accuracy: 1.0000 - val_loss: 3.1603 - val_accuracy: 0.6992\n",
            "Epoch 667/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8268e-04 - accuracy: 1.0000 - val_loss: 3.1582 - val_accuracy: 0.6992\n",
            "Epoch 668/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8161e-04 - accuracy: 1.0000 - val_loss: 3.1625 - val_accuracy: 0.6992\n",
            "Epoch 669/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7823e-04 - accuracy: 1.0000 - val_loss: 3.1656 - val_accuracy: 0.6911\n",
            "Epoch 670/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.8379e-04 - accuracy: 1.0000 - val_loss: 3.1612 - val_accuracy: 0.6992\n",
            "Epoch 671/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7927e-04 - accuracy: 1.0000 - val_loss: 3.1628 - val_accuracy: 0.6992\n",
            "Epoch 672/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7260e-04 - accuracy: 1.0000 - val_loss: 3.1671 - val_accuracy: 0.6992\n",
            "Epoch 673/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7857e-04 - accuracy: 1.0000 - val_loss: 3.1596 - val_accuracy: 0.6992\n",
            "Epoch 674/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7690e-04 - accuracy: 1.0000 - val_loss: 3.1693 - val_accuracy: 0.6992\n",
            "Epoch 675/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7857e-04 - accuracy: 1.0000 - val_loss: 3.1668 - val_accuracy: 0.6992\n",
            "Epoch 676/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7672e-04 - accuracy: 1.0000 - val_loss: 3.1674 - val_accuracy: 0.6992\n",
            "Epoch 677/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6991e-04 - accuracy: 1.0000 - val_loss: 3.1655 - val_accuracy: 0.6911\n",
            "Epoch 678/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7510e-04 - accuracy: 1.0000 - val_loss: 3.1644 - val_accuracy: 0.6992\n",
            "Epoch 679/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6768e-04 - accuracy: 1.0000 - val_loss: 3.1678 - val_accuracy: 0.6992\n",
            "Epoch 680/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7189e-04 - accuracy: 1.0000 - val_loss: 3.1726 - val_accuracy: 0.6992\n",
            "Epoch 681/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6513e-04 - accuracy: 1.0000 - val_loss: 3.1719 - val_accuracy: 0.6992\n",
            "Epoch 682/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7198e-04 - accuracy: 1.0000 - val_loss: 3.1748 - val_accuracy: 0.6992\n",
            "Epoch 683/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6866e-04 - accuracy: 1.0000 - val_loss: 3.1775 - val_accuracy: 0.6992\n",
            "Epoch 684/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.7733e-04 - accuracy: 1.0000 - val_loss: 3.1777 - val_accuracy: 0.6992\n",
            "Epoch 685/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6808e-04 - accuracy: 1.0000 - val_loss: 3.1784 - val_accuracy: 0.6992\n",
            "Epoch 686/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6211e-04 - accuracy: 1.0000 - val_loss: 3.1758 - val_accuracy: 0.6992\n",
            "Epoch 687/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6472e-04 - accuracy: 1.0000 - val_loss: 3.1765 - val_accuracy: 0.6992\n",
            "Epoch 688/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6315e-04 - accuracy: 1.0000 - val_loss: 3.1791 - val_accuracy: 0.6992\n",
            "Epoch 689/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6289e-04 - accuracy: 1.0000 - val_loss: 3.1773 - val_accuracy: 0.6992\n",
            "Epoch 690/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5874e-04 - accuracy: 1.0000 - val_loss: 3.1758 - val_accuracy: 0.6992\n",
            "Epoch 691/750\n",
            "123/123 [==============================] - 0s 3ms/step - loss: 4.5923e-04 - accuracy: 1.0000 - val_loss: 3.1839 - val_accuracy: 0.6992\n",
            "Epoch 692/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.6002e-04 - accuracy: 1.0000 - val_loss: 3.1815 - val_accuracy: 0.6992\n",
            "Epoch 693/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5512e-04 - accuracy: 1.0000 - val_loss: 3.1829 - val_accuracy: 0.6992\n",
            "Epoch 694/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5636e-04 - accuracy: 1.0000 - val_loss: 3.1822 - val_accuracy: 0.6992\n",
            "Epoch 695/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5508e-04 - accuracy: 1.0000 - val_loss: 3.1837 - val_accuracy: 0.6992\n",
            "Epoch 696/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5103e-04 - accuracy: 1.0000 - val_loss: 3.1805 - val_accuracy: 0.6911\n",
            "Epoch 697/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5637e-04 - accuracy: 1.0000 - val_loss: 3.1849 - val_accuracy: 0.6992\n",
            "Epoch 698/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5589e-04 - accuracy: 1.0000 - val_loss: 3.1862 - val_accuracy: 0.6992\n",
            "Epoch 699/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5023e-04 - accuracy: 1.0000 - val_loss: 3.1880 - val_accuracy: 0.6992\n",
            "Epoch 700/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5481e-04 - accuracy: 1.0000 - val_loss: 3.1876 - val_accuracy: 0.6992\n",
            "Epoch 701/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.5189e-04 - accuracy: 1.0000 - val_loss: 3.1878 - val_accuracy: 0.6992\n",
            "Epoch 702/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4847e-04 - accuracy: 1.0000 - val_loss: 3.1871 - val_accuracy: 0.6992\n",
            "Epoch 703/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4970e-04 - accuracy: 1.0000 - val_loss: 3.1888 - val_accuracy: 0.6992\n",
            "Epoch 704/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4796e-04 - accuracy: 1.0000 - val_loss: 3.1875 - val_accuracy: 0.6992\n",
            "Epoch 705/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4613e-04 - accuracy: 1.0000 - val_loss: 3.1904 - val_accuracy: 0.6992\n",
            "Epoch 706/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4505e-04 - accuracy: 1.0000 - val_loss: 3.1939 - val_accuracy: 0.6992\n",
            "Epoch 707/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4077e-04 - accuracy: 1.0000 - val_loss: 3.1887 - val_accuracy: 0.6992\n",
            "Epoch 708/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3865e-04 - accuracy: 1.0000 - val_loss: 3.1943 - val_accuracy: 0.6992\n",
            "Epoch 709/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4262e-04 - accuracy: 1.0000 - val_loss: 3.1920 - val_accuracy: 0.6992\n",
            "Epoch 710/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4119e-04 - accuracy: 1.0000 - val_loss: 3.1910 - val_accuracy: 0.6992\n",
            "Epoch 711/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4291e-04 - accuracy: 1.0000 - val_loss: 3.1973 - val_accuracy: 0.6992\n",
            "Epoch 712/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4026e-04 - accuracy: 1.0000 - val_loss: 3.1969 - val_accuracy: 0.6992\n",
            "Epoch 713/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.4017e-04 - accuracy: 1.0000 - val_loss: 3.1993 - val_accuracy: 0.6992\n",
            "Epoch 714/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3876e-04 - accuracy: 1.0000 - val_loss: 3.2017 - val_accuracy: 0.6992\n",
            "Epoch 715/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3448e-04 - accuracy: 1.0000 - val_loss: 3.1992 - val_accuracy: 0.6911\n",
            "Epoch 716/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3485e-04 - accuracy: 1.0000 - val_loss: 3.2028 - val_accuracy: 0.6992\n",
            "Epoch 717/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3667e-04 - accuracy: 1.0000 - val_loss: 3.1996 - val_accuracy: 0.6992\n",
            "Epoch 718/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3305e-04 - accuracy: 1.0000 - val_loss: 3.2029 - val_accuracy: 0.6992\n",
            "Epoch 719/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3491e-04 - accuracy: 1.0000 - val_loss: 3.2001 - val_accuracy: 0.6992\n",
            "Epoch 720/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3346e-04 - accuracy: 1.0000 - val_loss: 3.2009 - val_accuracy: 0.6992\n",
            "Epoch 721/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3206e-04 - accuracy: 1.0000 - val_loss: 3.2040 - val_accuracy: 0.6992\n",
            "Epoch 722/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3148e-04 - accuracy: 1.0000 - val_loss: 3.2005 - val_accuracy: 0.6992\n",
            "Epoch 723/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3070e-04 - accuracy: 1.0000 - val_loss: 3.2052 - val_accuracy: 0.6992\n",
            "Epoch 724/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2775e-04 - accuracy: 1.0000 - val_loss: 3.2073 - val_accuracy: 0.6992\n",
            "Epoch 725/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.3192e-04 - accuracy: 1.0000 - val_loss: 3.2058 - val_accuracy: 0.6992\n",
            "Epoch 726/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2785e-04 - accuracy: 1.0000 - val_loss: 3.2058 - val_accuracy: 0.6992\n",
            "Epoch 727/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2464e-04 - accuracy: 1.0000 - val_loss: 3.2104 - val_accuracy: 0.6992\n",
            "Epoch 728/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2987e-04 - accuracy: 1.0000 - val_loss: 3.2085 - val_accuracy: 0.6992\n",
            "Epoch 729/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2768e-04 - accuracy: 1.0000 - val_loss: 3.2070 - val_accuracy: 0.6992\n",
            "Epoch 730/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2289e-04 - accuracy: 1.0000 - val_loss: 3.2110 - val_accuracy: 0.6992\n",
            "Epoch 731/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2321e-04 - accuracy: 1.0000 - val_loss: 3.2085 - val_accuracy: 0.6992\n",
            "Epoch 732/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2259e-04 - accuracy: 1.0000 - val_loss: 3.2114 - val_accuracy: 0.6992\n",
            "Epoch 733/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2235e-04 - accuracy: 1.0000 - val_loss: 3.2142 - val_accuracy: 0.6992\n",
            "Epoch 734/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1801e-04 - accuracy: 1.0000 - val_loss: 3.2123 - val_accuracy: 0.6992\n",
            "Epoch 735/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2211e-04 - accuracy: 1.0000 - val_loss: 3.2145 - val_accuracy: 0.6992\n",
            "Epoch 736/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1982e-04 - accuracy: 1.0000 - val_loss: 3.2132 - val_accuracy: 0.6992\n",
            "Epoch 737/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1868e-04 - accuracy: 1.0000 - val_loss: 3.2146 - val_accuracy: 0.6992\n",
            "Epoch 738/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1928e-04 - accuracy: 1.0000 - val_loss: 3.2152 - val_accuracy: 0.6992\n",
            "Epoch 739/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1840e-04 - accuracy: 1.0000 - val_loss: 3.2150 - val_accuracy: 0.6992\n",
            "Epoch 740/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.2033e-04 - accuracy: 1.0000 - val_loss: 3.2150 - val_accuracy: 0.6992\n",
            "Epoch 741/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1625e-04 - accuracy: 1.0000 - val_loss: 3.2208 - val_accuracy: 0.6992\n",
            "Epoch 742/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1324e-04 - accuracy: 1.0000 - val_loss: 3.2207 - val_accuracy: 0.6911\n",
            "Epoch 743/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1467e-04 - accuracy: 1.0000 - val_loss: 3.2225 - val_accuracy: 0.6992\n",
            "Epoch 744/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1191e-04 - accuracy: 1.0000 - val_loss: 3.2175 - val_accuracy: 0.6992\n",
            "Epoch 745/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1293e-04 - accuracy: 1.0000 - val_loss: 3.2222 - val_accuracy: 0.6992\n",
            "Epoch 746/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1155e-04 - accuracy: 1.0000 - val_loss: 3.2219 - val_accuracy: 0.6992\n",
            "Epoch 747/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.1071e-04 - accuracy: 1.0000 - val_loss: 3.2234 - val_accuracy: 0.6992\n",
            "Epoch 748/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.0703e-04 - accuracy: 1.0000 - val_loss: 3.2233 - val_accuracy: 0.6992\n",
            "Epoch 749/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.0737e-04 - accuracy: 1.0000 - val_loss: 3.2214 - val_accuracy: 0.6992\n",
            "Epoch 750/750\n",
            "123/123 [==============================] - 0s 2ms/step - loss: 4.0762e-04 - accuracy: 1.0000 - val_loss: 3.2247 - val_accuracy: 0.6992\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt \n",
        "acc = hist.history['accuracy']\n",
        "val_acc = hist.history['val_accuracy']\n",
        "loss = hist.history['loss']\n",
        "val_loss = hist.history['val_loss']\n",
        " \n",
        "epochs = range(len(acc))\n",
        " \n",
        "plt.plot(epochs, acc, 'b', label='Training acc')\n",
        "plt.plot(epochs, val_acc, 'r', label='Validation acc')\n",
        "plt.title('Training and validation accuracy')\n",
        "plt.legend()\n",
        "plt.savefig('custom_trainvalacc.png')\n",
        "plt.figure()\n",
        " \n",
        "plt.plot(epochs, loss, 'b', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.legend()\n",
        " \n",
        "#plt.show()\n",
        "plt.savefig('custom_trainvalloss.png')\n",
        "plt.figure()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 580
        },
        "id": "ork5MhiAMeoc",
        "outputId": "8229d8e2-f54e-450f-aebc-a3f0541bf0c3"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {},
          "execution_count": 23
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {
            "needs_background": "light"
          }
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 432x288 with 0 Axes>"
            ]
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "res = model.evaluate(x_testing,y_testing)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AYjt_zydRa3K",
        "outputId": "ed8586f2-834b-4626-8022-0b7a7ffd0a91"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "5/5 [==============================] - 0s 2ms/step - loss: 0.5221 - accuracy: 0.7468\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "test = x_testing[0]\n",
        "y_act=y_testing[0]\n",
        "result = model.predict(test.reshape(1,8))\n",
        "result"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FKDSfwqmR5Di",
        "outputId": "75dc3888-77bd-485a-9ee7-d88dd881fa27"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[0.23537347, 0.76462656]], dtype=float32)"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "y_pred =np.round(result)\n",
        "print(\"Actual:\"+str(y_act))\n",
        "print(\"Predicted:\"+str(y_pred))"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "I98SQPA1TSXp",
        "outputId": "2c28e41c-2227-4553-dc10-ca0d99da8365"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Actual:[1. 0.]\n",
            "Predicted:[[0. 1.]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "QEMvEyV4Tv14"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}